---
title: "When User Input Lines Are Blurred: Indirect Prompt Injection Attack Vulnerabilities in AI LLMs"
date: 2025-01-05
categories: 
  - "cybersecurity"
  - "security"
  - "vulnerabilities"
tags: 
  - "cybersecurity"
  - "penetration_testing"
  - "penetrationtesting"
  - "security"
  - "vulnerability"
---

It was a cold and wet Thursday morning, sometime in early 2006. There I was sitting at the very top back row of an awe-inspiring lecture theatre inside Royal Holloway's Founder’s Building in Egham, Surrey (UK) while studying for my MSc in Information Security. Back then, the lecture in progress was from the software security module.

![](https://track.hubspot.com/__ptq.gif?a=21158977&k=14&r=https%3A%2F%2Fwww.trustwave.com%2Fen-us%2Fresources%2Fblogs%2Fspiderlabs-blog%2Fwhen-user-input-lines-are-blurred-indirect-prompt-injection-attack-vulnerabilities-in-ai-llms%2F&bu=https%253A%252F%252Fwww.trustwave.com%252Fen-us%252Fresources%252Fblogs%252Fspiderlabs-blog&bvt=rss)

Go to Source
