<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<style type=text/css>body{font-family:monospace;}</style>
	<title>The Hollywood Sign is Not on Fire: Deepfakes Spread During L.A. Wildfires</title>
	
	
	<link rel="stylesheet" href="/css/style.css">
	
	
</head>
<body>
	<header>
	==========================<br>
	== <a href="https://ghariib.ir/">Gharib Personal Blog</a> ==<br>
	==========================
	<div style="float: right;">A Techi Personal Blog</div><br>
	<p>
	<nav>
			<a href="/"><b>Start</b></a>.
			
			
			<a href="/posts/"><b>Posts</b></a>.
			
			<a href="/categories/"><b>Categories</b></a>.
			
			<a href="/tags/"><b>Tags</b></a>.
			
	</nav>
	</p>
	
</header>

	
	<main>
		<article>
			<h1>The Hollywood Sign is Not on Fire: Deepfakes Spread During L.A. Wildfires</h1>
			<b><time>12.01.2025 00:00</time></b>
		       
		           <a href="/tags/comprehensive">comprehensive</a>
        	       
		           <a href="/tags/technology">technology</a>
        	       

			<div>
				<p>
<figure>
  <img src="https://www.mcafee.com/blogs/wp-content/uploads/2025/01/300x200_Blog_Hollywoodd-300x200.png" alt="" />
</figure>


</p>
<p>Amid the devastation of the Los Angeles County wildfires – scorching an area twice the size of Manhattan – McAfee threat researchers have identified and verified a rise in AI-generated deepfakes and misinformation, including startling but false images of the Hollywood sign engulfed in flames.</p>
<h2 id="debunking-the-myth-hollywood-sign-safe-amid-wildfire-rumors-on-social-media">Debunking the Myth: Hollywood Sign Safe Amid Wildfire Rumors on Social Media</h2>
<p>Social media and local broadcast news have been flooded with deceptive images claiming the Hollywood sign is engulfed in flames, with many people alleging that the iconic landmark is “surrounded by fire.” </p>
<p>
<figure>
  <img src="https://www.mcafee.com/blogs/wp-content/uploads/2025/01/CleanShot-2025-01-10-at-17.23.03.jpg" alt="" />
</figure>


</p>
<p><strong>Figure 1.</strong> AI-generated image shared on Facebook on January 9th, 2025.</p>
<p><strong>Fact check:</strong> The Hollywood sign is still standing and is intact. A live feed of the Hollywood sign clearly shows the sign is not currently in harm’s way or engulfed in flames.</p>
<p>
<figure>
  <img src="https://www.mcafee.com/blogs/wp-content/uploads/2025/01/CleanShot-2025-01-10-at-17.27.05.jpg" alt="" />
</figure>


</p>
<p><strong>Figure 2:</strong> Live view of the Hollywood sign taken at 3.29 PT on Friday, January 10th 2025.</p>
<p>McAfee researchers have examined dozens of images shared across X, Facebook, Tik Tok and Instagram, and have verified these are indeed AI-generated images and videos. In addition to analysis from our own threat researchers, McAfee’s image deepfake detection technology has flagged images shown here (and many more) of the Hollywood Hills as AI-generated, with the fire serving as a key factor in its analysis.</p>
<p>McAfee’s investigation traced many of the images back to Gemini, an AI-based image generation platform. This finding underscores the increasing sophistication of fake image synthesis, where fake images and videos can be created in mere seconds, but can be spread to more than a million views in just 24 hours, such as is the case with the social post shared on Facebook below.</p>
<p>
<figure>
  <img src="https://www.mcafee.com/blogs/wp-content/uploads/2025/01/CleanShot-2025-01-10-at-17.36.03.jpg" alt="" />
</figure>


</p>
<p><strong>Figure 3:</strong> Screenshot of deepfake video of Hollywood sign on fire. This video was discovered on Facebook and had already achieved 1.3 million views in 24 hours.</p>
<p>McAfee CTO, Steve Grobman states, “AI tools have supercharged the spread of disinformation and misinformation, enabling false content—like recent fake images of the Hollywood sign engulfed in flames—to circulate at unprecedented speed. This makes it critical for social media users to keep their guard up, approach viral posts with skepticism, and verify sources to distinguish fact from fiction.”</p>
<p>
<figure>
  <img src="https://www.mcafee.com/blogs/wp-content/uploads/2025/01/CleanShot-2025-01-10-at-12.50.12.jpg" alt="" />
</figure>



<figure>
  <img src="https://www.mcafee.com/blogs/wp-content/uploads/2025/01/heatmap-upscaled-cropped.jpg" alt="" />
</figure>


</p>
<p><strong>Figure 4.</strong> McAfee’s advanced AI models identifies images that have been modified or created using AI. The heatmap depicts areas that have been used to identify and confirm AI-usage.</p>
<h2 id="when-social-media-fans-the-flames-of-misinformation">When Social Media Fans the Flames of Misinformation </h2>
<p>AI-generated still images are incredibly easy to produce. In less than a minute, we were able to produce a convincing image of the Hollywood Hills sign on fire for free with AI image generating Android app (we have not published these images, only those found on social media). Many of these apps exist to choose from. Some do filter for violent and other objectionable content. However, images like the Hollywood Hills sign on fire, fall outside of normal guardrails. Additionally, the business model of many of these apps include free credits as a trial, making it quick and easy to create and share. AI image generation is a widely available and easily accessible tool used in many misinformation campaigns.</p>
<p>See below for more examples:</p>
<p>
<figure>
  <img src="https://www.mcafee.com/blogs/wp-content/uploads/2025/01/CleanShot-2025-01-10-at-14.58.48.jpg" alt="" />
</figure>


</p>
<p><strong>Figure 5.</strong> Examples on Instagram.</p>
<p>Upon closer inspection, some images had watermark images clearly labeled from Generative AI tools such as Grok. And while this might be an obvious telltale sign for some people, there are many others who are not familiar with or recognize such watermarks.</p>
<p>
<figure>
  <img src="https://www.mcafee.com/blogs/wp-content/uploads/2025/01/GguZu4qW0AANhpY.jpeg" alt="" />
</figure>


</p>
<p>
<figure>
  <img src="https://www.mcafee.com/blogs/wp-content/uploads/2025/01/CleanShot-2025-01-10-at-10.20.58.jpg" alt="" />
</figure>


</p>
<p><strong>Figure 6.</strong> The Grok watermark is clearly visible in the image above.</p>
<h2 id="how-to-identify-a-deepfake">How to Identify a Deepfake</h2>
<p>There are several straightforward steps that you can take to spot a fake. We recommend a combination of healthy skepticism and awareness combined with the right technology, such as McAfee Deepfake Detector.</p>
<p>While not all AI is malicious or ‘bad’, this technology is commonly used by bad actors for malicious intent when it comes to deepfake scams, misinformation and disinformation. While the deepfakes outlined here appear to be without malicious intent –  other than to misinform social media users – we could expect these to evolve where scammers create similar deepfakes as part of fake donation scams, and so we advise everyone to stay vigilant and learn more on how to spot deepfakes online:</p>
<ul>
<li><strong>Consider who did the posting. Verify who posted the content.</strong> If it’s a friend, did they repost it? Who was the original poster? Could it be a bot or a bogus account? How long has the account been active? What kind of other posts have popped up on it? If an organization posted it, look it up online. Does it seem reputable? This bit of detective work might not provide a definitive answer, but it can let you know if something seems fishy.</li>
<li><strong>Seek another source.</strong> Whether they aim to spread disinformation, commit fraud, or rile up emotions, malicious deepfakes try to pass themselves off as legitimate. Consider a video clip that looks like it got recorded at a press conference. The figure behind the podium says some outrageous things. Did that really happen? Consult other established and respected sources. If they’re not reporting on it, you’re likely dealing with a deepfake.</li>
<li><strong>Zoom in</strong>. A close look at deepfake photos or videos often reveals inconsistencies and flat-out oddities. This could come in the form of six fingers on one hand, or perhaps the skin looks too smooth or there’s something strange with the smile – these are all telltale signs.</li>
<li><strong>Practice healthy skepticism. Always</strong>: With AI tools improving so quickly, we can no longer take things at face value. Malicious deepfakes look to deceive, defraud, and disinform. And the people who create them hope you’ll consume their content in one, unthinking gulp. Scrutiny is key today. Fact-checking a must, particularly as deepfakes look sharper and sharper as the technology evolves.</li>
</ul>
<p>Plenty of deepfakes can lure you into sketchy corners of the internet. Places where malware and phishing sites take root. Consider using comprehensive online protection software with McAfee+ and McAfee Deepfake Detector to keep safe. In addition to several features that protect your devices, privacy, and identity, they can warn you of unsafe sites too.</p>
<p>The post The Hollywood Sign is Not on Fire: Deepfakes Spread During L.A. Wildfires appeared first on McAfee Blog.</p>

			</div>
		</article>
	</main>
<aside>
	<div>
		<div>
			<h3>LATEST POSTS</h3>
		</div>
		<div>
			<ul>
				
				<li><a href="/posts/2025-03-20-cve-2025-2557---audi-utr-dashcam-20-com/">CVE-2025-2557 - Audi UTR Dashcam 20 Command API Local Network Access Control Vulnerability</a></li>
				
				<li><a href="/posts/2025-03-20-cve-2025-29980---etrakitnet-sql-injecti/">CVE-2025-29980 - eTRAKiTnet SQL Injection Vulnerability</a></li>
				
				<li><a href="/posts/2025-03-20-cve-2025-30160---redlib-deflate-decompr/">CVE-2025-30160 - Redlib DEFLATE Decompression Bomb Denial-of-Service Vulnerability</a></li>
				
				<li><a href="/posts/2025-03-20-cve-2025-29217---tenda-w18e-stack-overf/">CVE-2025-29217 - Tenda W18E Stack Overflow Denial of Service Vulnerability</a></li>
				
				<li><a href="/posts/2025-03-20-cve-2025-29218---tenda-w18e-stack-overf/">CVE-2025-29218 - Tenda W18E Stack Overflow Vulnerability</a></li>
				
			</ul>
		</div>
	</div>
</aside>


	<footer>
	<p>&copy; 2025 <a href="https://ghariib.ir/"><b>Alireza Gharib. All right reserved</b></a>.
	<a href="https://github.com/Gharib110"><b>Github</b></a>.
	</p>
</footer>

</body>
</html>
