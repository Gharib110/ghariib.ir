<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<style type=text/css>body{font-family:monospace;}</style>
	<title>&lt;div&gt;A Privacy Model for Classical &amp; Learned Bloom Filters&lt;/div&gt;</title>
	
	
	<link rel="stylesheet" href="/css/style.css">
	
	
</head>
<body>
	<header>
	==========================<br>
	== <a href="https://ghariib.ir/">Gharib Personal Blog</a> ==<br>
	==========================
	<div style="float: right;">A Techi Personal Blog</div><br>
	<p>
	<nav>
			<a href="/"><b>Start</b></a>.
			
			
			<a href="/posts/"><b>Posts</b></a>.
			
			<a href="/categories/"><b>Categories</b></a>.
			
			<a href="/tags/"><b>Tags</b></a>.
			
	</nav>
	</p>
	
</header>

	
	<main>
		<article>
			<h1>&lt;div&gt;A Privacy Model for Classical &amp; Learned Bloom Filters&lt;/div&gt;</h1>
			<b><time>29.01.2025 00:00</time></b>
		       
		           <a href="/tags/cryptography">cryptography</a>
        	       
		           <a href="/tags/security">security</a>
        	       

			<div>
				<p>ePrint Report: <strong>A Privacy Model for Classical &amp; Learned Bloom Filters</strong><br>
<em>Hayder Tirmazi</em></p>
<p>The Classical Bloom Filter (CBF) is a class of Probabilistic Data Structures (PDS) for handling Approximate Query Membership (AMQ). The Learned Bloom Filter (LBF) is a recently proposed class of PDS that combines the Classical Bloom Filter with a Learning Model while preserving the Bloom Filter&rsquo;s one-sided error guarantees. Bloom Filters have been used in settings where inputs are sensitive and need to be private in the presence of an adversary with access to the Bloom Filter through an API or in the presence of an adversary who has access to the internal state of the Bloom Filter. Prior work has investigated the privacy of the Classical Bloom Filter providing attacks and defenses under various privacy definitions. In this work, we formulate a stronger differential privacy-based model for the Bloom Filter. We propose constructions of the Classical and Learned Bloom Filter that satisfy $(epsilon, 0)$-differential privacy. This is also the first work that analyses and addresses the privacy of the Learned Bloom Filter under any rigorous model, which is an open problem.</p>
<p>Go to Source</p>

			</div>
		</article>
	</main>
<aside>
	<div>
		<div>
			<h3>LATEST POSTS</h3>
		</div>
		<div>
			<ul>
				
				<li><a href="/posts/2025-03-22-cve-2025-2618---d-link-dap-1620-heap-ba/">CVE-2025-2618 - D-Link DAP-1620 Heap-Based Buffer Overflow Vulnerability</a></li>
				
				<li><a href="/posts/2025-03-22-cve-2025-2619---d-link-dap-1620-stack-b/">CVE-2025-2619 - D-Link DAP-1620 Stack-Based Buffer Overflow Vulnerability</a></li>
				
				<li><a href="/posts/2025-03-22-cve-2025-2186---funnelkit-woocommerce-s/">CVE-2025-2186 - FunnelKit WooCommerce SQL Injection</a></li>
				
				<li><a href="/posts/2025-03-22-cve-2025-2617---yangyouwang-crud-cross-/">CVE-2025-2617 - Yangyouwang Crud Cross-Site Scripting Vulnerability</a></li>
				
				<li><a href="/posts/2025-03-22-cve-2025-26796---apache-oozie-cross-sit/">CVE-2025-26796 - Apache Oozie Cross-site Scripting Vulnerability</a></li>
				
			</ul>
		</div>
	</div>
</aside>


	<footer>
	<p>&copy; 2025 <a href="https://ghariib.ir/"><b>Alireza Gharib. All right reserved</b></a>.
	<a href="https://github.com/Gharib110"><b>Github</b></a>.
	</p>
</footer>

</body>
</html>
