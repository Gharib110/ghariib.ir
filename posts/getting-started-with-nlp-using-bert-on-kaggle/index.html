<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<style type=text/css>body{font-family:monospace;}</style>
	<title>Getting started with NLP using Bert on Kaggle</title>
	
	
	<link rel="stylesheet" href="/css/style.css">
	
	
</head>
<body>
	<header>
	==========================<br>
	== <a href="https://ghariib.ir/">Gharib Personal Blog</a> ==<br>
	==========================
	<div style="float: right;">A Techi Personal Blog</div><br>
	<p>
	<nav>
			<a href="/"><b>Start</b></a>.
			
			
			<a href="/posts/"><b>Posts</b></a>.
			
			<a href="/categories/"><b>Categories</b></a>.
			
			<a href="/tags/"><b>Tags</b></a>.
			
	</nav>
	</p>
	
</header>

	
	<main>
		<article>
			<h1>Getting started with NLP using Bert on Kaggle</h1>
			<b><time>29.01.2025 00:00</time></b>
		       

			<div>
				<h2 id="1import-and-eda">1、Import and EDA</h2>
<pre tabindex="0"><code>import os
iskaggle = os.environ.get(&#39;KAGGLE_KERNEL_RUN_TYPE&#39;, &#39;&#39;)
from pathlib import Path
if iskaggle:
    path = Path(&#39;/kaggle/input/us-patent-phrase-to-phrase-matching&#39;)
</code></pre><pre tabindex="0"><code>import pandas as pd
df = pd.read_csv(path/&#39;train.csv&#39;)
df[&#39;input&#39;] = &#39;TEXT1: &#39; + df.context + &#39;; TEXT2: &#39; + df.target + &#39;; ANC1: &#39; + df.anchor
df.input.head()
</code></pre><h2 id="2tokenization">2、Tokenization</h2>
<pre tabindex="0"><code>from datasets import Dataset, DatasetDict
ds = Dataset.from_pandas(df)
import warnings,logging,torch
warnings.simplefilter(&#39;ignore&#39;)
logging.disable(logging.WARNING)
model_nm = &#39;anferico/bert-for-patents&#39;
# Load model directly
from transformers import AutoModelForSequenceClassification, AutoTokenizer
model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)
tokenizer = AutoTokenizer.from_pretrained(&#39;anferico/bert-for-patents&#39;)
</code></pre><pre tabindex="0"><code>def tok_func(x):
    return tokenizer(x[&#39;input&#39;])
# Tokenize all the sentences using the tokenizer
tok_ds = ds.map(tok_func, batched=True)
tok_ds = tok_ds.rename_columns({&#39;score&#39;:&#39;labels&#39;})
</code></pre><h2 id="3test-and-validation-sets">3、Test and Validation sets</h2>
<pre tabindex="0"><code>eval_df = pd.read_csv(path/&#39;test.csv&#39;)
dds = tok_ds.train_test_split(0.25, seed=42)
eval_df[&#39;input&#39;] = &#39;TEXT1: &#39; + eval_df.context + &#39;; TEXT2: &#39; + eval_df.target + &#39;; ANC1: &#39; + eval_df.anchor
eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)
</code></pre><h2 id="4metrics-and-correlation">4、Metrics and Correlation</h2>
<pre tabindex="0"><code>import numpy as np
def corr(x,y): 
    ## change the 2-d array into 1-d array
    return np.corrcoef(x.flatten(), y)[0,1]
def corr_d(eval_pred): return {&#39;pearson&#39;: corr(*eval_pred)}
</code></pre><h2 id="5training-our-model">5、Training our model</h2>
<pre tabindex="0"><code>from transformers import TrainingArguments,Trainer
bs = 128
epochs = 4
lr = 8e-5
args = TrainingArguments(&#39;outputs&#39;, learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type=&#39;cosine&#39;, fp16=True,
    evaluation_strategy=&#34;epoch&#34;, per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,
    num_train_epochs=epochs, weight_decay=0.01, report_to=&#39;none&#39;)
trainer = Trainer(model, args, train_dataset=dds[&#39;train&#39;], eval_dataset=dds[&#39;test&#39;],
                  tokenizer=tokenizer, compute_metrics=corr_d)
trainer.train()
</code></pre><p>
<figure>
  <img src="https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fials6lciimf07ahsxw39.png" alt="Image description" />
</figure>


</p>
<h2 id="6get-the-predictions-on-the-test-set">6、Get the predictions on the test set</h2>
<pre tabindex="0"><code>preds = trainer.predict(eval_ds).predictions.astype(float)
preds = np.clip(preds, 0, 1)
import datasets

submission = datasets.Dataset.from_dict({
    &#39;id&#39;: eval_ds[&#39;id&#39;],
    &#39;score&#39;: preds
})

submission.to_csv(&#39;submission.csv&#39;, index=False)
</code></pre><p>Go to Source</p>

			</div>
		</article>
	</main>
<aside>
	<div>
		<div>
			<h3>LATEST POSTS</h3>
		</div>
		<div>
			<ul>
				
				<li><a href="/posts/a-visual-summary-of-sans-new2cyber-summit-2025/">A Visual Summary of SANS New2Cyber Summit 2025</a></li>
				
				<li><a href="/posts/advance-your-cybersecurity-career-how-to-use-tuition-reimbursement-for-sec406/">Advance Your Cybersecurity Career: How to Use Tuition Reimbursement for SEC406</a></li>
				
				<li><a href="/posts/continuous-penetration-testing-a-consultants-perspective/">Continuous Penetration Testing - A Consultant’s Perspective</a></li>
				
				<li><a href="/posts/desktop-4-39-smarter-ai-agent-docker-desktop-cli-in-ga-and-effortless-multi-platform-builds/">Desktop 4.39: Smarter AI Agent, Docker Desktop CLI in GA, and Effortless Multi-Platform Builds</a></li>
				
				<li><a href="/posts/docker-engine-v28-hardening-container-networking-by-default/">Docker Engine v28: Hardening Container Networking by Default</a></li>
				
			</ul>
		</div>
	</div>
</aside>


	<footer>
	<p>&copy; 2025 <a href="https://ghariib.ir/"><b>Alireza Gharib. All right reserved</b></a>.
	<a href="https://github.com/Gharib110"><b>Github</b></a>.
	</p>
</footer>

</body>
</html>
