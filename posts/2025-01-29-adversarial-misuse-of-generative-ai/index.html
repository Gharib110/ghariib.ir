<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<style type=text/css>body{font-family:monospace;}</style>
	<title>Adversarial Misuse of Generative AI</title>
	
	
	<link rel="stylesheet" href="/css/style.css">
	
	
</head>
<body>
	<header>
	==========================<br>
	== <a href="https://ghariib.ir/">Gharib Personal Blog</a> ==<br>
	==========================
	<div style="float: right;">A Techi Personal Blog</div><br>
	<p>
	<nav>
			<a href="/"><b>Start</b></a>.
			
			
			<a href="/posts/"><b>Posts</b></a>.
			
			<a href="/categories/"><b>Categories</b></a>.
			
			<a href="/tags/"><b>Tags</b></a>.
			
	</nav>
	</p>
	
</header>

	
	<main>
		<article>
			<h1>Adversarial Misuse of Generative AI</h1>
			<b><time>29.01.2025 14:00</time></b>
		       

			<div>
				<h1 id="adversarial-misuse-of-generative-ai">Adversarial Misuse of Generative AI</h1>
<p>Rapid advancements in artificial intelligence (AI) are unlocking new possibilities for the way we work and accelerating innovation in science, technology, and beyond. In cybersecurity, AI is poised to transform digital defense, empowering defenders and enhancing our collective security. Large language models (LLMs) open new possibilities for defenders, from sifting</p>
<p>Rapid advancements in artificial intelligence (AI) are unlocking new possibilities for the way we work and accelerating innovation in <a href="https://deepmind.google/technologies/alphafold/">science</a>, <a href="https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/">technology</a>, and beyond. In cybersecurity, AI is poised to transform digital defense, <a href="https://blog.google/technology/safety-security/google-ai-cyber-defense-initiative/">empowering defenders and enhancing our collective security</a>. Large language models (LLMs) open new possibilities for defenders, from sifting through complex telemetry to <a href="https://cloud.google.com/products/gemini/code-assist">secure coding</a>, <a href="https://googleprojectzero.blogspot.com/2024/10/from-naptime-to-big-sleep.html">vulnerability</a> <a href="https://security.googleblog.com/2024/11/leveling-up-fuzzing-finding-more.html">discovery</a>, and streamlining operations. However, some of these same AI capabilities are also available to attackers, leading to understandable anxieties about the potential for AI to be misused for malicious purposes. </p>
<p>Much of the current discourse around cyber threat actors&rsquo; misuse of AI is confined to theoretical research. While these studies demonstrate the potential for malicious exploitation of AI, they don&rsquo;t necessarily reflect the reality of how AI is currently being used by threat actors in the wild. To bridge this gap, we are sharing a comprehensive analysis of how threat actors interacted with Google&rsquo;s AI-powered assistant, Gemini. Our analysis was grounded by the expertise of Google&rsquo;s Threat Intelligence Group (GTIG), which combines decades of experience tracking threat actors on the front lines and protecting Google, our users, and our customers from government-backed attackers, targeted 0-day exploits, coordinated information operations (IO), and serious cyber crime networks.</p>
<p>We believe the private sector, governments, educational institutions, and other stakeholders <a href="https://blog.google/technology/ai/a-policy-agenda-for-responsible-ai-progress-opportunity-responsibility-security/">must work together</a> to maximize AI&rsquo;s benefits while also <a href="https://blog.google/technology/safety-security/google-ai-saif-risk-assessment/">reducing the risks</a> of abuse. At Google, we are committed to developing responsible AI guided by <a href="https://ai.google/responsibility/principles/#our-ai-principles-in-action">our principles</a>, and we share <a href="https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/">resources</a> and <a href="https://ai.google.dev/responsible/docs">best practices</a> to enable responsible AI development across the industry. We continuously improve <a href="https://blog.google/technology/ai/">our AI models</a> to make them <a href="https://gemini.google/policy-guidelines/">less susceptible to misuse</a>, and we apply our intelligence to improve Google&rsquo;s defenses and protect users from cyber threat activity. We also proactively disrupt malicious activity to protect our users and help make the internet safer. We share our findings with the security community to raise awareness and enable stronger protections for all. </p>
<p>aside_block</p>
<p>&lt;ListValue: [StructValue([(&rsquo;title&rsquo;, &lsquo;Adversarial Misuse of Generative AI&rsquo;), (&lsquo;body&rsquo;, &lt;wagtail.rich_text.RichText object at 0x3e3ef37646d0&gt;), (&lsquo;btn_text&rsquo;, &lsquo;Download now&rsquo;), (&lsquo;href&rsquo;, &lsquo;<a href="https://services.google.com/fh/files/misc/adversarial-misuse-generative-ai.pdf')">https://services.google.com/fh/files/misc/adversarial-misuse-generative-ai.pdf')</a>, (&lsquo;image&rsquo;, &lt;GAEImage: adversarial gen AI cover&gt;)])]&gt;</p>
<h2 id="executive-summary">Executive Summary</h2>
<p>Google Threat Intelligence Group (GTIG) is committed to tracking and protecting against cyber threat activity. We relentlessly defend Google, our users, and our customers by building the most complete threat picture to disrupt adversaries. As part of that effort, we investigate activity associated with threat actors to protect against malicious activity, including the misuse of generative AI or LLMs. </p>
<p>This report shares our findings on government-backed threat actor use of the Gemini web application. The report encompasses new findings across advanced persistent threat (APT) and coordinated information operations (IO) actors tracked by GTIG. By using a mix of analyst review and LLM-assisted analysis, we investigated prompts by APT and IO threat actors who attempted to misuse Gemini.</p>
<p><em><strong>Advanced Persistent Threat (APT)</strong> refers to government-backed hacking activity, including cyber espionage and destructive computer network attacks.</em>  </p>
<p><em><strong>Information Operations (IO)</strong> attempt to influence online audiences in a deceptive, coordinated manner. Examples include sockpuppet accounts and comment brigading.</em> </p>
<p>GTIG takes a holistic, intelligence-driven approach to detecting and disrupting threat activity, and our understanding of government-backed threat actors and their campaigns provides the needed context to identify threat enabling activity. We use a wide variety of technical signals to track government-backed threat actors and their infrastructure, and we are able to correlate those signals with activity on our platforms to protect Google and our users. By tracking this activity, we’re able to leverage our insights to counter threats across Google platforms, including disrupting the activity of threat actors who have misused Gemini. We also actively share our insights with the public to raise awareness and enable stronger protections across the wider ecosystem.</p>
<p>Our analysis of government-backed threat actor use of Gemini focused on understanding how threat actors are using AI in their operations and if any of this activity represents novel or unique AI-enabled attack or abuse techniques. Our findings, which are consistent with those of our industry peers, reveal that while AI can be a useful tool for threat actors, it is not yet the game-changer it is sometimes portrayed to be. While we do see threat actors using generative AI to perform common tasks like troubleshooting, research, and content generation, we do not see indications of them developing novel capabilities. </p>
<p>Our key findings include:</p>
<ul>
<li><strong>We did not observe any original or persistent attempts by threat actors to use prompt attacks or other machine learning (ML)-focused threats as outlined in the</strong> <a href="https://saif.google/secure-ai-framework/risks"><strong>Secure AI Framework (SAIF) risk taxonomy</strong></a><strong>.</strong> Rather than engineering tailored prompts, threat actors used more basic measures or publicly available jailbreak prompts in unsuccessful attempts to bypass Gemini&rsquo;s safety controls. </li>
<li><strong>Threat actors are experimenting with Gemini to enable their operations, finding productivity gains but not yet developing novel capabilities</strong>. At present, they primarily use AI for research, troubleshooting code, and creating and localizing content. </li>
<li><strong>APT actors used Gemini to support several phases of the attack lifecycle</strong>, including researching potential infrastructure and free hosting providers, reconnaissance on target organizations, research into vulnerabilities, payload development, and assistance with malicious scripting and evasion techniques. Iranian APT actors were the heaviest users of Gemini, using it for a wide range of purposes. Of note, we observed limited use of Gemini by Russian APT actors during the period of analysis.</li>
<li><strong>IO actors used Gemini for research; content generation including developing personas and messaging; translation and localization; and to find ways to increase their reach</strong>. Again, Iranian IO actors were the heaviest users of Gemini, accounting for three quarters of all use by IO actors. We also observed Chinese and Russian IO actors using Gemini primarily for general research and content creation. </li>
<li><strong>Gemini&rsquo;s safety and security measures restricted content that would enhance adversary capabilities</strong> as observed in this dataset. Gemini provided assistance with common tasks like creating content, summarizing, explaining complex concepts, and even simple coding tasks. Assisting with more elaborate or explicitly malicious tasks generated safety responses from Gemini. </li>
<li><strong>Threat actors attempted unsuccessfully to use Gemini to enable abuse of Google products,</strong> including researching techniques for Gmail phishing, stealing data, coding a Chrome infostealer, and bypassing Google&rsquo;s account verification methods. </li>
</ul>
<p>Rather than enabling disruptive change, generative AI allows threat actors to move faster and at higher volume. For skilled actors, generative AI tools provide a helpful framework, similar to the use of Metasploit or Cobalt Strike in cyber threat activity. For less skilled actors, they also provide a learning and productivity tool, enabling them to more quickly develop tools and incorporate existing techniques. However, <strong>current LLMs on their own are unlikely to enable breakthrough capabilities for threat actors</strong>. <strong><strong>We note that the AI landscape is in constant flux, with new AI models and agentic systems emerging daily. As this evolution unfolds, GTIG anticipates the threat landscape to evolve in stride as threat actors adopt new AI technologies in their operations</strong></strong>.</p>
<h2 id="ai-focused-threats">AI-Focused Threats</h2>
<p>Attackers can use LLMs in two ways. One way is attempting to leverage LLMs to accelerate their campaigns (e.g., by generating code for malware or content for phishing emails). The overwhelming majority of activity we observed falls into this category. The second way attackers can use LLMs is to instruct a model or AI agent to take a malicious action (e.g., finding sensitive user data and exfiltrating it). These risks are outlined in Google&rsquo;s <a href="https://saif.google/secure-ai-framework/risks">Secure AI Framework (SAIF) risk taxonomy</a>. </p>
<p><strong>We did not observe any original or persistent attempts by threat actors to use prompt attacks or other AI-specific threats.</strong> Rather than engineering tailored prompts, threat actors used more basic measures, such as rephrasing a prompt or sending the same prompt multiple times. These attempts were unsuccessful.</p>
<h3 id="jailbreak-attempts-basic-and-based-on-publicly-available-prompts">Jailbreak Attempts: Basic and Based on Publicly Available Prompts</h3>
<p>We observed a handful of cases of low-effort experimentation using publicly available jailbreak prompts in unsuccessful attempts to bypass Gemini&rsquo;s safety controls. Threat actors copied and pasted publicly available prompts and appended small variations in the final instruction (e.g., basic instructions to create ransomware or malware). Gemini responded with safety fallback responses and declined to follow the threat actor&rsquo;s instructions. </p>
<p>In one example of a failed jailbreak attempt, an APT actor copied publicly available prompts into Gemini and appended basic instructions to perform coding tasks. These tasks included encoding text from a file and writing it to an executable and writing Python code for a distributed denial-of-service (DDoS) tool. In the former case, Gemini provided Python code to convert Base64 to hex, but provided a safety filtered response when the user entered a follow-up prompt that requested the same code as a VBScript.</p>
<p>The same group used a different publicly available jailbreak prompt to request Python code for DDoS. Gemini provided a safety filtered response stating that it could not assist, and the threat actor abandoned the session and did not attempt further interaction.</p>
<p><em><strong>What is an AI jailbreak?</strong></em> </p>
<p><em>Jailbreaks are one type of <a href="https://saif.google/secure-ai-framework/risks">Prompt Injection attack</a>, causing an AI model to behave in ways that they&rsquo;ve been trained to avoid (e.g., outputting unsafe content or leaking sensitive information). Prompt Injections generally cause the LLM to execute malicious &ldquo;injected&rdquo; instructions as part of data that were not meant to be executed by the LLM.</em> </p>
<p><em>Controls against prompt injection include input/output validation and sanitization as well as adversarial training and testing. Training, tuning, and evaluation processes also help fortify models against prompt injection.</em></p>
<p>
<figure>
  <img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/adversarial-gen-ai.max-1000x1000.png" alt="Example of a jailbreak prompt publicly available on Github" />
</figure>


</p>
<p>Example of a jailbreak prompt publicly available <a href="https://github.com/elder-plinius/L1B3RT4S/blob/main/GOOGLE.mkd">on GitHub</a></p>
<p>Some malicious actors unsuccessfully attempted to prompt Gemini for guidance on abusing Google products, such as advanced phishing techniques for Gmail, assistance coding a Chrome infostealer, and methods to bypass Google&rsquo;s account creation verification methods. These attempts were unsuccessful. Gemini did not produce malware or other content that could plausibly be used in a successful malicious campaign. Instead, the responses consisted of safety-guided content and generally helpful, neutral advice about coding and cybersecurity. In our continuous work to protect Google and our users, we have not seen threat actors either expand their capabilities or better succeed in their efforts to bypass Google&rsquo;s defenses.</p>
<h2 id="findings-government-backed-threat-actors-misusing-gemini">Findings: Government-Backed Threat Actors Misusing Gemini</h2>
<p><strong>At a Glance: Government-Backed Attackers</strong></p>
<p>Government-backed attackers attempted to use Gemini for coding and scripting tasks, gathering information about potential targets, researching publicly known vulnerabilities, and enabling post-compromise activities, such as defense evasion in a target environment. </p>
<ul>
<li><strong>Iran</strong>: Iranian APT actors were the heaviest users of Gemini, using it for a wide range of purposes, including research on defense organizations, vulnerability research, and creating content for campaigns. APT42 focused on crafting phishing campaigns, conducting reconnaissance on defense experts and organizations, and generating content with cybersecurity themes. </li>
<li><strong>China</strong>: Chinese APT actors used Gemini to conduct reconnaissance, for scripting and development, to troubleshoot code, and to research how to obtain deeper access to target networks. They focused on topics such as lateral movement, privilege escalation, data exfiltration, and detection evasion. </li>
<li><strong>North Korea</strong>: North Korean APT actors used Gemini to support several phases of the attack lifecycle, including researching potential infrastructure and free hosting providers, reconnaissance on target organizations, payload development, and assistance with malicious scripting and evasion techniques. They also used Gemini to research topics of strategic interest to the North Korean government, such as the South Korean military and cryptocurrency. Of note, North Korean actors also used Gemini to draft cover letters and research jobs—activities that would likely support North Korea&rsquo;s efforts to <a href="https://cloud.google.com/blog/topics/threat-intelligence/mitigating-dprk-it-worker-threat">place clandestine IT workers</a> at Western companies. </li>
<li><strong>Russia</strong>: With Russian APT actors, we observed limited use of Gemini during the period of analysis. Their Gemini use focused on coding tasks, including converting publicly available malware into another coding language and adding encryption functions to existing code.</li>
</ul>
<p>Google analyzed Gemini activity associated with known APT actors and identified APT groups from more than 20 countries that used Gemini. The highest volume of usage was from Iran and China. APT actors used Gemini to support several phases of the attack lifecycle, including researching potential infrastructure and free hosting providers, reconnaissance on target organizations, research into vulnerabilities, payload development, and assistance with malicious scripting and evasion techniques. The top use cases by APT actors focused on: </p>
<ul>
<li>
<p>Assistance with coding tasks, including troubleshooting, tool and script development and converting or rewriting existing code </p>
</li>
<li>
<p>Vulnerability research focused on publicly reported vulnerabilities and specific CVEs </p>
</li>
<li>
<p>General research on various technologies, translations and technical explanations </p>
</li>
<li>
<p>Reconnaissance about likely targets, including details about specific organizations </p>
</li>
<li>
<p>Enabling post-compromise activity, such seeking advice on techniques to evade detection, escalate privileges or conduct internal reconnaissance in a target environment</p>
</li>
</ul>
<p>We observed APT actors use Gemini attempting to support all phases of the attack lifecycle.</p>
<p><strong>Attack Lifecycle</strong></p>
<p><strong>Topics of Gemini Usage</strong></p>
<p><strong>Reconnaissance</strong></p>
<p>Attacker gathers information about the target</p>
<p><strong>Iran</strong></p>
<ul>
<li>
<p>Recon on experts, international defense organizations, government organizations</p>
</li>
<li>
<p>Topics related to Iran-Israel proxy conflict</p>
</li>
</ul>
<p><strong>North Korea</strong></p>
<ul>
<li>
<p>Research on companies across multiple sectors and geos</p>
</li>
<li>
<p>Recon on US military and operations in South Korea </p>
</li>
<li>
<p>Research free hosting providers</p>
</li>
</ul>
<p><strong>China</strong></p>
<ul>
<li>
<p>Research on US military, US-based IT service providers </p>
</li>
<li>
<p>Understand public database of US intelligence personnel  </p>
</li>
<li>
<p>Research on target network ranges; determine domain names of targets </p>
</li>
</ul>
<p><strong>Weaponization</strong></p>
<p>Attacker develops or acquires tools to exploit target</p>
<ul>
<li>
<p>Develop webcam recording code in C++</p>
</li>
<li>
<p>Convert Chrome infostealer function from Python to Node.js</p>
</li>
<li>
<p>Rewrite publicly available malware into another language</p>
</li>
<li>
<p>Add AES encryption functionality to provided code</p>
</li>
</ul>
<p><strong>Delivery</strong></p>
<p>Attacker delivers weaponized exploit or payload to the target system</p>
<ul>
<li>
<p>Better understanding advanced phishing techniques</p>
</li>
<li>
<p>Generating content for targeting a US defense organization</p>
</li>
<li>
<p>Generating content with cybersecurity and AI themes</p>
</li>
</ul>
<p><strong>Exploitation</strong></p>
<p>Attacker exploits vulnerability to gain access</p>
<ul>
<li>
<p>Reverse engineer endpoint detection and response (EDR) server components for health check and authentication</p>
</li>
<li>
<p>Access Microsoft Exchange using password hash</p>
</li>
<li>
<p>Research vulnerabilities in WinRM protocol</p>
</li>
<li>
<p>Understand publicly reported vulnerabilities, including Internet of Things (IoT) bugs</p>
</li>
</ul>
<p><strong>Installation</strong></p>
<p>Attacker installs tools or malware to maintain access</p>
<ul>
<li>
<p>Sign an Outlook Visual Studio Tools for Office (VSTO) plug-in and deploy it silently to all computers</p>
</li>
<li>
<p>Add a self-signed certificate to Active Directory</p>
</li>
<li>
<p>Research Mimikatz for Windows 11</p>
</li>
<li>
<p>Research Chrome extensions that provide parental controls and monitoring</p>
</li>
</ul>
<p><strong>Command and control (C2)</strong></p>
<p>Attacker establishes communication channel with the compromised system</p>
<ul>
<li>
<p>Generate code to remotely access Windows Event Log</p>
</li>
<li>
<p>Active Directory management commands</p>
</li>
<li>
<p>JSON Web Token (JWT) security and routing rules in Ruby on Rails</p>
</li>
<li>
<p>Character encoding issues in smbclient</p>
</li>
<li>
<p>Command to check IPs of admins on the domain controller</p>
</li>
</ul>
<p><strong>Actions on objectives</strong></p>
<p>Attacker achieves their intended goal such as data theft or disruption</p>
<ul>
<li>
<p>Automate workflows with Selenium (e.g. logging into compromised account)</p>
</li>
<li>
<p>Generate a PHP script to extract emails from Gmail into electronic mail (EML) files</p>
</li>
<li>
<p>Upload large files to OneDrive</p>
</li>
<li>
<p>Solution to TLS 1.3 visibility challenges</p>
</li>
</ul>
<p>
<figure>
  <img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/iran-misuse-ai.max-1000x1000.png" alt="Iran AI misuse" />
</figure>


</p>
<h3 id="iranian-government-backed-actors">Iranian Government-Backed Actors </h3>
<p>Iranian government-backed actors accounted for the largest Gemini use linked to APT actors. Across Iranian government-backed actors, we observed a broad scope of research and use cases, including to enable reconnaissance on targets, for research into publicly reported vulnerabilities, to request translation and technical explanations, and to create content for possible use in future campaigns. Their use reflected strategic Iranian interests including research focused on defense organizations and experts, defense systems, foreign governments, individual dissidents, the Israel-Hamas conflict, and social issues in Iran.</p>
<p><strong>At a Glance: Iranian APT Actors Using Gemini</strong></p>
<ul>
<li><strong>Over 10 Iran-backed groups</strong> observed using Gemini</li>
<li><strong>Google abuse-focused use cases:</strong> 
<ul>
<li>
<ul>
<li>Researching methods for extracting data from Android devices, including SMS messages, accounts, contacts, and social media accounts</li>
</ul>
</li>
</ul>
</li>
<li><strong>Example use cases:</strong> 
<ul>
<li>
<ul>
<li>Coding and scripting 
<ul>
<li>
<ul>
<li>PowerShell and Linux commands</li>
<li>Python code for website scraping</li>
<li>Debugging and improving a Ghidra script </li>
<li>Developing PHP scripts to collect and store user IP addresses and browser information in a MySQL database</li>
<li>Assistance with C# programming</li>
<li>Modifying assembly code </li>
<li>Help understanding error messages</li>
</ul>
</li>
</ul>
</li>
<li>Vulnerability research
<ul>
<li>
<ul>
<li>Research on specific CVEs and technologies, such as WinRM and IoT devices</li>
<li>Exploitation techniques and proof-of-concept code </li>
<li>Research on server-side request forgery (SSRF) exploitation techniques</li>
<li>Research on the open-source router exploitation tool RomBuster </li>
</ul>
</li>
</ul>
</li>
<li>Research about organizations 
<ul>
<li>
<ul>
<li>International defense organizations</li>
<li>Military and government organizations </li>
<li>Cybersecurity companies</li>
<li>International organizations that monitor development of advanced weapons</li>
</ul>
</li>
</ul>
</li>
<li>Research about warfare defenses
<ul>
<li>
<ul>
<li>Information on the Iran-Israel proxy conflict</li>
<li>Unmanned aerial vehicles (UAV)</li>
<li>Anti-drone systems</li>
<li>Satellite technology</li>
<li>Remote sensing technology</li>
<li>Israel defense systems</li>
</ul>
</li>
</ul>
</li>
<li>Generating content
<ul>
<li>
<ul>
<li>Generating content with cybersecurity and AI themes </li>
<li>Tailoring content to target a defense organization</li>
<li>Translating various texts into Farsi, Hebrew, and English</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="crafting-phishing-campaigns">Crafting Phishing Campaigns </h4>
<p>Over 30% of Iranian APT actors&rsquo; Gemini use was linked to APT42. APT42&rsquo;s Gemini activity reflected the group&rsquo;s focus on crafting successful phishing campaigns. We observed the group using Gemini to conduct reconnaissance into individual policy and defense experts, as well as organizations of interest for the group. </p>
<p>In addition to reconnaissance, APT42 used the text generation and editing capabilities of Gemini to craft material for phishing campaigns, including generating content with cybersecurity themes and tailoring the output to a US defense organization. APT42 also utilized Gemini for translation including localization, or tailoring content for a local audience. This includes content tailored to local culture and local language, such as asking for translations to be in fluent English.</p>
<h4 id="vulnerability-research">Vulnerability Research</h4>
<p>The majority of APT42&rsquo;s efforts focused on research into publicly known vulnerabilities, such as a request to generate a list of critical vulnerabilities from 2023. They also focused on vulnerabilities in specific products such as Mikrotik, Apereo, and Atlassian.</p>
<p>Of note, APT42 appeared to be researching how to use generative AI tools for offensive purposes, asking Gemini for help preparing training content for a red team focused on how offensive teams can use AI tools in their operations.  </p>
<h4 id="research-into-military-and-weapons-systems">Research Into Military and Weapons Systems </h4>
<p>APT42 also appears to have used Gemini&rsquo;s translation and explanation functions to better understand publicly available information on defense systems. Their efforts included general research into the Israel-Hamas conflict, as well as strategic trends in China&rsquo;s defense industry. The threat actor also used Gemini for technical explanations about US-made aerospace systems.</p>
<p>Another Iranian APT group also focused on understanding warfare defenses including specific research into satellite signal jamming and anti-drone systems. Other Iranian APT actors researched specific defense systems, including researching information about specific unmanned aerial vehicle (UAV) models, jamming F-35 fighter jets, anti-drone systems, and Israel&rsquo;s missile defense systems. </p>
<p>
<figure>
  <img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/china-misuse-ai.max-1000x1000.png" alt="China AI misuse" />
</figure>


</p>
<h3 id="peoples-republic-of-china-prc-government-backed-actors">People’s Republic of China (PRC) Government-Backed Actors</h3>
<p>Government-backed actors linked to the People&rsquo;s Republic of China (PRC) attempted to use Gemini to enable reconnaissance on targets, for scripting and development, to request translation and explanation of technical concepts, and attempting to enable deeper access to a network following initial compromise. PRC threat actors&rsquo; usage resembled an IT admin seeking to streamline, troubleshoot, or automate their tasks. In a malicious context, however, this activity could be used to enable lateral movement, privilege escalation, data exfiltration, and detection evasion.</p>
<p><strong>At a Glance: People&rsquo;s Republic of China APT Actors Using Gemini</strong></p>
<ul>
<li><strong>Over 20 China-backed groups</strong> observed using Gemini</li>
<li><strong>Notable use cases:</strong> 
<ul>
<li>
<ul>
<li>Reconnaissance
<ul>
<li>
<ul>
<li>Research US military and US-based IT organizations</li>
<li>Gather US government network ranges</li>
<li>Understand publicly available information about US intelligence community personnel </li>
<li>Determine domain names of targets spanning eight countries, mostly government agencies</li>
<li>Access Microsoft Exchange using password hash</li>
</ul>
</li>
</ul>
</li>
<li>Vulnerability research
<ul>
<li>
<ul>
<li>Reverse engineer Carbon Black EDR&rsquo;s server components for health check and authentication</li>
</ul>
</li>
</ul>
</li>
<li>Scripting and development
<ul>
<li>
<ul>
<li>Generate code to remotely access Windows Event Log</li>
<li>Active Directory management commands</li>
</ul>
</li>
</ul>
</li>
<li>Translation and explanation
<ul>
<li>
<ul>
<li>Understand graph databases (Nebula Graph)</li>
<li>Solutions to TLS 1.3 visibility challenges</li>
<li>Understand a malicious PHP script</li>
<li>Web JWT security and routing rules in Ruby on Rails</li>
</ul>
</li>
</ul>
</li>
<li>Deeper system access and post-compromise actions 
<ul>
<li>
<ul>
<li>Sign an Outlook VSTO plug-in and deploy it silently to all computers</li>
<li>Add a self-signed certificate to Active Directory</li>
<li>Upload large files to OneDrive</li>
<li>Character encoding issues in smbclient</li>
<li>Command to check IPs of admins on the Domain Controller</li>
<li>Record passwords on the VMware vCenter</li>
<li>Impacket troubleshooting</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="enabling-deeper-access-in-a-target-network">Enabling Deeper Access in a Target Network </h4>
<p>PRC-backed APT actors also used Gemini to work through scripting and development tasks, many of which appeared intended to enable deeper access in a target network after threat actors obtained initial access. For example, one PRC-backed group asked Gemini for assistance figuring out how to sign a plugin for Microsoft Outlook and silently deploy it to all computers. The same actor also asked Gemini to generate code to remotely access Windows Event Log; sought instructions on how to add a self-signed certificate to Active Directory; and asked Gemini for a command to identify the IP addresses of administrators on the domain controller. Other actors used Gemini for help troubleshooting Chinese character encoding issues in smbclient and how to record passwords on the VMware vCenter. </p>
<p>In another example, PRC-backed APT actors asked Gemini for assistance with Active Directory management commands and requested help troubleshooting impacket, a Python-based tool for working with network protocols. While impacket is commonly used for benign purposes, the context of the threat actor made it clear that the actor was using the tool for malicious purposes. </p>
<h4 id="explaining-tools-concepts-and-code">Explaining Tools, Concepts, and Code </h4>
<p>PRC actors utilized Gemini to learn about specific tools and technologies and develop solutions to technical challenges. For example, a PRC APT actor used Gemini to break down how to use the graph database Nebula Graph. In another instance, the same actor used Gemini to offer possible solutions to TLS 1.3 visibility challenges. Another PRC-backed APT group sought to understand a malicious PHP script. </p>
<h4 id="vulnerability-research-and-reverse-engineering">Vulnerability Research and Reverse Engineering</h4>
<p>In one case, a PRC-backed APT actor attempted unsuccessfully to get Gemini&rsquo;s help reverse engineering the endpoint detection and response (EDR) tool Carbon Black. The same threat actor copied disassembled Python bytecode into Gemini to convert the bytecode into Python code. It&rsquo;s not clear what their objective was. </p>
<h4 id="unsuccessful-attempts-to-elicit-internal-system-information-from-gemini">Unsuccessful Attempts to Elicit Internal System Information From Gemini</h4>
<p>In one case, the PRC-backed APT actor APT41 attempted unsuccessfully to use Gemini to learn about Gemini&rsquo;s underlying infrastructure and systems. The actor asked Gemini to share details such as its IP address, kernel version, and network configuration. Gemini responded but did not disclose sensitive information. In a helpful tone, the responses provided publicly available details that would be widely known about the topic, while also indicating that the requested information is kept secret to prevent unauthorized access. </p>
<p>
<figure>
  <img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/nk-misuse-ai.max-1000x1000.png" alt="north Korea AI misuse" />
</figure>


</p>
<h3 id="north-korean-government-backed-actors">North Korean Government-Backed Actors</h3>
<p>North Korean APT actors used Gemini to support several phases of the attack lifecycle, including researching potential infrastructure and free hosting providers, reconnaissance on target organizations, payload development, and assistance with malicious scripting and evasion techniques. They also used Gemini to research topics of strategic interest to the North Korean government, such as South Korean nuclear technology and cryptocurrency. We also observed that North Korean actors were using LLMs in likely attempts to enable North Korea&rsquo;s efforts to <a href="https://cloud.google.com/blog/topics/threat-intelligence/mitigating-dprk-it-worker-threat">place clandestine IT workers</a> at Western companies.</p>
<p><strong>At a Glance: North Korean APT Actors Using Gemini</strong></p>
<ul>
<li><strong>Nine North Korea-backed groups</strong> observed using Gemini</li>
<li><strong>Google-focused use cases:</strong> 
<ul>
<li>
<ul>
<li>Research advanced techniques for phishing Gmail</li>
<li>Scripting to steal data from compromised Gmail accounts</li>
<li>Understanding a Chrome extension that provides parental controls (capable of taking screenshots, keylogging)</li>
<li>Convert Chrome infostealer function from Python to Node.js</li>
<li>Bypassing restrictions on Google Voice </li>
<li>Generate code snippets for a Chrome extension </li>
</ul>
</li>
</ul>
</li>
<li><strong>Notable use cases:</strong> 
<ul>
<li>
<ul>
<li>Enabling clandestine IT worker scheme 
<ul>
<li>
<ul>
<li>Best Discord servers for freelancers</li>
<li>Exchange with overseas employees </li>
<li>Jobs on LinkedIn </li>
<li>Average salary</li>
<li>Drafting work proposals</li>
<li>Generate cover letters from job postings</li>
</ul>
</li>
</ul>
</li>
<li>Research on topics 
<ul>
<li>
<ul>
<li>Free hosting providers </li>
<li>Cryptocurrency</li>
<li>Operational technology (OT) and industrial networks </li>
<li>Nuclear technology and power plants in South Korea</li>
<li>Historic cyber events (e.g., major worms and DDoS attacks; Russia-Ukraine conflict) and cyber forces of foreign militaries</li>
</ul>
</li>
</ul>
</li>
<li>Research about organizations 
<ul>
<li>
<ul>
<li>Companies across 11 sectors and 13 countries</li>
<li>South Korean military </li>
<li>US military </li>
<li>German defense organizations</li>
</ul>
</li>
</ul>
</li>
<li>Malware development </li>
<li>Evasion techniques</li>
<li>Automating workflows for logging into compromised accounts </li>
<li>Understanding Mimikatz for Windows 11 </li>
<li>Scripting and troubleshooting</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="clandestine-it-worker-threat">Clandestine IT Worker Threat</h4>
<p>North Korean APT actors used Gemini to draft cover letters and research jobs—activities that would likely support <a href="https://cloud.google.com/blog/topics/threat-intelligence/mitigating-dprk-it-worker-threat">efforts by North Korean nationals</a> to use fake identities and obtain freelance and full-time jobs at foreign companies while concealing their true identities and locations. One North Korea-backed group utilized Gemini to draft cover letters and proposals for job descriptions, researched average salaries for specific jobs, and asked about jobs on LinkedIn. The group also used Gemini for information about overseas employee exchanges. Many of the topics would be common for anyone researching and applying for jobs. </p>
<p>While normally employment-related research would be typical for any job seeker, we assess the usage is likely related to North Korea&rsquo;s <a href="https://www.ic3.gov/Media/Y2024/PSA240516">ongoing efforts</a> to place clandestine workers in freelance gigs or full-time jobs at Western firms. The scheme, which <a href="https://www.justice.gov/usao-dc/pr/charges-and-seizures-brought-fraud-scheme-aimed-denying-revenue-workers-associated-north">involves</a> thousands of North Korean workers and <a href="https://www.justice.gov/usao-dc/pr/charges-and-seizures-brought-fraud-scheme-aimed-denying-revenue-workers-associated-north">has affected</a> hundreds of US-based companies, uses IT workers with false identities to complete freelance work and send wages back to the North Korean regime.</p>
<p><strong>North Korea’s AI toolkit</strong> </p>
<p>Outside of their use of Gemini, North Korean cyber threat actors have shown a long-standing interest in AI tools. They likely use AI applications to augment malicious operations and improve efficiency and capabilities, and for producing content to support their campaigns, such as phishing lures and profile photos for fake personas. We assess with high confidence that North Korean cyber threat actors will continue to demonstrate an interest in these emerging technologies for the foreseeable future. </p>
<p>DPRK IT Workers</p>
<p>We have observed <a href="https://cloud.google.com/blog/topics/threat-intelligence/mitigating-dprk-it-worker-threat">DPRK IT Workers</a> leverage accounts on assistive writing tools, Monica (monica.im) and Ahrefs (ahrefs.com), which could potentially aid the group&rsquo;s work despite a lack of language fluency. Additionally, the group has maintained accounts on Data Annotation Tech, a company hiring individuals to train AI models. Notably, a profile photo used by a suspected IT worker bore a noticeable resemblance to multiple different images on the internet, suggesting that a manipulation tool was used to generate the threat actor&rsquo;s profile photo. </p>
<p>APT43</p>
<p>Google Threat Intelligence Group (GTIG) has detected evidence of <a href="https://cloud.google.com/blog/topics/threat-intelligence/apt43-north-korea-cybercrime-espionage">APT43</a> actors accessing multiple publicly available LLM tools; however, the intended purpose is not clear. Based on the capabilities of these platforms and historical APT43 activities, it is possible these applications could be used in the creation of rapport-building emails, lure content, and malicious PowerShell and scripting efforts. </p>
<ul>
<li>
<p>GTIG has detected APT43 actors reference publicly available AI chatbot tools alongside the topic &ldquo;북핵 해결&rdquo; (translation: &ldquo;North Korean nuclear issue solution&rdquo;), indicating the group is using AI applications to conduct technical research as well as open-source analysis on South Korean foreign and military affairs and nuclear issues. </p>
</li>
<li>
<p>GTIG has identified APT43 actors accessing multiple publicly available AI image generation tools, including tools used for image manipulation and creating realistic-looking human portraits. </p>
</li>
</ul>
<h4 id="target-research-and-reconnaissance">Target Research and Reconnaissance</h4>
<p>North Korean actors also engaged with Gemini with several questions that appeared focused on conducting initial research and reconnaissance into prospective targets. They also researched organizations and industries that are typical targets for North Korean actors, including the US and South Korean militaries and defense contractors. One North Korean APT group asked Gemini for information about companies and organizations across a variety of industry sectors and regions. Some of this Gemini usage related directly to organizations that the same group had attempted to target in phishing and malware campaigns that Google previously detected and disrupted.</p>
<p>In addition to research into companies, North Korean APT actors researched nuclear technology and power plants in South Korea, such as site locations, recent news articles, and the security status of the plants. Gemini responded with widely available, public information and facts that would be easily discoverable in an online search. </p>
<h4 id="help-with-scripting-payload-development-defense-evasion">Help with Scripting, Payload Development, Defense Evasion </h4>
<p>North Korean actors also tried to use Gemini to assist with development and scripting tasks. One North Korea-backed group attempted to use Gemini to help develop webcam recording code in C++. Gemini provided multiple versions of code, and repeated efforts by the actor potentially suggested their frustration by Gemini&rsquo;s answers. The same group also asked Gemini to generate a robots.txt file to block crawlers and an .htaccess file to redirect all URLs except CSS extensions. </p>
<p>One North Korean APT actor used Gemini for assistance developing code for sandbox evasion. For example, the threat actor utilized Gemini to write code in C++ to detect VM environments and Hyper-V virtual machines. Gemini provided responses with short code snippets to perform simple sandbox checks. The same group also sought help troubleshooting Java errors when implementing AES encryption, and separately asked Gemini if it is possible to acquire a system password on Windows 11 using Mimikatz. </p>
<p>
<figure>
  <img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/russia-misuse-ai.max-1000x1000.png" alt="Russia AI misuse" />
</figure>


</p>
<h3 id="russian-government-backed-actors">Russian Government-Backed Actors </h3>
<p>During the period of analysis, we observed limited use of Gemini by Russia-backed APT actors. Of this limited use, the majority of usage appeared benign, rather than threat-enabling. The reasons for this low engagement are unclear. It is possible Russian actors avoided Gemini out of operational security considerations, staying off Western-controlled platforms to avoid monitoring of their activities. They may be using AI tools produced by Russian firms or locally hosting LLMs, which would ensure full control of their infrastructure. Alternatively, they may have favored other Western LLMs.</p>
<p>One Russian government-backed group used Gemini to request help with a handful of tasks, including help rewriting publicly available malware into another language, adding encryption functionality to code, and explanations for how a specific block of publicly available malicious code functions.</p>
<p><strong>At a Glance: Russian APT Actors Using Gemini</strong></p>
<ul>
<li><strong>Three Russia-backed groups</strong> observed using Gemini</li>
<li><strong>Notable use cases:</strong> 
<ul>
<li>
<ul>
<li>Scripting
<ul>
<li>
<ul>
<li>Help rewriting public malware into another language</li>
</ul>
</li>
</ul>
</li>
<li>Payload crafting
<ul>
<li>
<ul>
<li>Add AES encryption functionality to provided code</li>
</ul>
</li>
</ul>
</li>
<li>Translation and explanation 
<ul>
<li>
<ul>
<li>Understand how some public malicious code works</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="financially-motivated-actors-using-llms">Financially Motivated Actors Using LLMs</h3>
<p>Threat actors in underground marketplaces are advertising ways to bypass security guardrails to help LLMs with malware development, phishing, and other malicious tasks. The offerings include jailbroken LLMs that are ready-made for malicious use. </p>
<p>Throughout 2023 and 2024, Google Threat Intelligence Group (GTIG) observed underground forum posts related to LLMs, indicating there is a burgeoning market for nefarious versions of LLMs. Some advertisements boast customized and jailbroken LLMs that don&rsquo;t have restrictions for malware development purposes, or they tout a lack of security measures typically found on legitimate services, allowing the user to prompt the LLM about any topic or task without incurring security guardrails or limits on their queries. <a href="https://www.darkreading.com/threat-intelligence/fraudgpt-malicious-chatbot-for-sale-dark-web">Examples</a> <a href="https://krebsonsecurity.com/2023/08/meet-the-brains-behind-the-malware-friendly-ai-chat-service-wormgpt/">include</a> FraudGPT, which has been advertised on Telegram as having no limitations, and WormGPT, a privacy focused, &ldquo;uncensored&rdquo; LLM capable of developing malware.   </p>
<p>Financially motivated actors are using LLMs to help augment business email compromise (BEC) operations. GTIG has noted evidence of financially motivated actors using manipulated video and voice content in business email compromise (BEC) scams. Media reports indicate that financially motivated actors have reportedly used WormGPT to create more persuasive BEC messages.</p>
<h2 id="findings-information-operations-io-actors-misusing-gemini">Findings: Information Operations (IO) Actors Misusing Gemini</h2>
<p><strong>At a Glance: Information Operations Actors</strong> </p>
<p>IO actors attempted to use Gemini for research, content generation, translation and localization, and to find ways to increase their reach.</p>
<ul>
<li><strong>Iran:</strong> Iranian IO actors used Gemini for a wide range of tasks, accounting for three quarters of all IO prompts. They used Gemini for content creation and manipulation, including generating articles, rewriting text with a specific tone, and optimizing it for better reach. Their activity also focused on translation and localization, adapting content for different audiences, and for general research into news, current events, and political issues. </li>
<li><strong>China</strong>: Pro-China IO actors used Gemini primarily for general research on various topics, including a variety of topics of strategic interest to the Chinese government. The most prolific IO actor we track, DRAGONBRIDGE, was responsible for the majority of this activity. They also used Gemini to research current events and politics, and in a few cases, they used Gemini to generate articles or content on specific topics.</li>
<li><strong>Russia</strong>: Russian IO actors used Gemini primarily for general research, content creation, and translation. For example, their use involved assistance drafting content, rewriting article titles, and planning social media campaigns. Some activity demonstrated an interest in developing AI capabilities, asking for information on tools for creating online AI chatbots, developer tools for interacting with LLMs, and options for textual content analysis.</li>
</ul>
<p>IO actors used Gemini for research, content generation including developing personas and messaging, translation and localization, and to find ways to increase their reach. Common use cases include general research into news and current events as well as specific research into individuals and organizations. In addition to creating content for campaigns, including personas and content, the actors researched increasing the efficacy of campaigns, including automating distribution, using search engine optimization (SEO) to optimize the reach of campaigns, and increasing operational security. As with government-backed groups, IO actors also used Gemini for translation and localization and for understanding the meanings or context of content. </p>
<p>
<figure>
  <img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/iran-misuse-io.max-1000x1000.png" alt="Iran misuse IO" />
</figure>


</p>
<h3 id="iran-linked-information-operations-actors">Iran-Linked Information Operations Actors</h3>
<p>Iran-based information operations (IO) groups used Gemini for a wide range of tasks, including general research, translation and localization, content creation and manipulation, and generating content with a specific bias or tone. We also observed Iran-based IO actors engage with Gemini about news events and ask Gemini to provide details on economic and political issues in Iran, the US, the Middle East, and Europe.</p>
<p>In line with their practice of mixing original and borrowed content, Iranian IO actors translated existing material, including news-like articles. They then used Gemini to explain the context and meaning of particular phrases within the given text.</p>
<p>Iran-based IO actors also used Gemini to localize the content, seeking human-like translation and asking Gemini for help with tasks like making the text sound like a native English speaker. They used Gemini to manipulate text (e.g., asking for help rewriting existing text on immigration and crime in a specific style or tone). </p>
<p>Iran&rsquo;s activity also included research about improving the reach of their campaigns. For example, they attempted to generate SEO-optimized content, likely in an effort to reach a larger audience. Some actors also used Gemini to suggest strategies for increasing engagement on social media.</p>
<p><strong>At a Glance: Iran-Linked IO Actors Using Gemini</strong></p>
<ul>
<li><strong>Eight Iran-linked IO groups</strong> observed using Gemini </li>
<li><strong>Example use cases:</strong> 
<ul>
<li>
<ul>
<li>Content creation - text 
<ul>
<li>
<ul>
<li>Generate article titles</li>
<li>Generate SEO-optimized content and titles</li>
<li>Draft a report critical of Bahrain </li>
<li>Draft titles and hashtags in English and Farsi for videos that are catchy or create urgency to watch the content</li>
<li>Draft titles and descriptions promoting Islam</li>
</ul>
</li>
</ul>
</li>
<li>Translation - content in / out of native language
<ul>
<li>
<ul>
<li>Translate into Farsi-provided texts about a variety of topics, including the Iranian election, human rights, international law, Islam, and other topics</li>
<li>Translate Farsi-language idioms and proverbs to other languages</li>
<li>Translate news about the US economy, US government, and politics into Farsi, using a specified tone</li>
<li>Draft a French-language headline to get viewers to engage with specific content</li>
</ul>
</li>
</ul>
</li>
<li>Content manipulation - copy editing to refine content
<ul>
<li>
<ul>
<li>Reformulate specific text about Sharia law</li>
<li>Paraphrase content describing specific improvements to Iran&rsquo;s export economy</li>
<li>Rewrite a provided text about diplomacy and economic challenges with countries like China and Germany</li>
<li>Provide synonyms for specific words or phrases</li>
<li>Rewrite provided text about Islam and Iraq in different styles or tones</li>
<li>Proofread provided content </li>
</ul>
</li>
</ul>
</li>
<li>Content creation - biased text
<ul>
<li>
<ul>
<li>Generate or reformulate text to criticize a government minister and other individuals for failures or other actions</li>
<li>Describe how a popular American TV show perpetuates harmful stereotypes</li>
<li>Generate Islam-themed titles for thumbnail previews on social media</li>
</ul>
</li>
</ul>
</li>
<li>General research - news and events
<ul>
<li>
<ul>
<li>Provide an overview of current events in specific regions</li>
<li>Research about the Iran-Iraq war</li>
<li>Define specific terms</li>
<li>Suggest social media channels for information about Islam and the Quran</li>
<li>Provide information on countries&rsquo; policies toward the Middle East</li>
</ul>
</li>
</ul>
</li>
<li>Create persona - photo generation
<ul>
<li>
<ul>
<li>Create a logo</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>
<figure>
  <img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/china-misuse-io.max-1000x1000.png" alt="China misuse IO" />
</figure>


</p>
<h3 id="prc-linked-information-operations-actors">PRC-Linked Information Operations Actors</h3>
<p>IO actors linked to the People&rsquo;s Republic of China (PRC) used Gemini primarily for general research on a wide variety of topics. The most prolific IO actor we track, the pro-China group <a href="https://blog.google/threat-analysis-group/google-disrupted-dragonbridge-activity-q1-2024/">DRAGONBRIDGE</a>, was responsible for approximately three quarters of this activity. Of their activity, the majority use was general research about a wide variety of topics, ranging from details about the features of various social media platforms to questions about various topics of strategic interest to the PRC government. Actors researched information on current events and politics in other regions, with a focus on the US and Taiwan. They also showed interest in assessing the impact and risk of certain events. In a handful of cases, DRAGONBRIDGE used Gemini to generate articles or content on specific topics.</p>
<p><strong>At a Glance: PRC-Linked IO Actors Using Gemini</strong></p>
<ul>
<li><strong>Three PRC-linked IO groups</strong> observed using Gemini </li>
<li><strong>Example use cases:</strong> 
<ul>
<li>
<ul>
<li>General research - political and social topics
<ul>
<li>
<ul>
<li>Research about specific countries, organizations, and individuals </li>
<li>Research relations between specific countries and China</li>
<li>Research on topics sensitive to the the Chinese government (e.g., five poisons) </li>
<li>Research on Taiwanese politicians and their actions toward China</li>
<li>Research on US politics and political figures and their attitudes on China</li>
<li>Research foreign press coverage about China</li>
<li>Summarize key takeaways from a video</li>
</ul>
</li>
</ul>
</li>
<li>General research - technology 
<ul>
<li>
<ul>
<li>Compare functionality and features of different social media platforms </li>
<li>Explain technical concepts and suggestions for useful tools</li>
</ul>
</li>
</ul>
</li>
<li>Translation - content in / out of native language 
<ul>
<li>
<ul>
<li>Translate and summarize text between Chinese and other languages </li>
</ul>
</li>
</ul>
</li>
<li>Content creation - text
<ul>
<li>
<ul>
<li>Draft articles on topics such as the use of AI and social movements in specific regions</li>
<li>Generate a summary of a movie trailer about a Chinese dissident</li>
</ul>
</li>
</ul>
</li>
<li>Create persona - text generation
<ul>
<li>
<ul>
<li>Generate a company profile for a media company</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>DRAGONBRIDGE has experimented with other generative AI tools to create synthetic content in support of their IO campaigns. As early as 2022, the group <a href="https://public-assets.graphika.com/reports/graphika-report-deepfake-it-till-you-make-it.pdf">used</a> a commercial AI service in videos on YouTube to depict AI-generated news presenters. Their use of AI-generated video <a href="https://blog.google/threat-analysis-group/google-disrupted-dragonbridge-activity-q1-2024/">continued</a> through 2024 but has not resulted in significantly higher engagement from real viewers. Google detected and <a href="https://blog.google/threat-analysis-group/tag-bulletin-q4-2024/">terminated</a> the channels distributing this content immediately upon discovery. DRAGONBRIDGE&rsquo;s use of AI-generated videos or images <a href="https://blog.google/threat-analysis-group/google-disrupted-dragonbridge-activity-q1-2024/">has not resulted</a> in significantly higher engagement from real viewers.</p>
<p>
<figure>
  <img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/russia-misuse-io.max-1000x1000.png" alt="Russia misuse IO" />
</figure>


</p>
<h3 id="russia-linked-information-operations-actors">Russia-Linked Information Operations Actors</h3>
<p>Russian IO actors used Gemini for general research, content creation, and translation. Half of this activity was associated with the Russian IO actor we track as <a href="https://services.google.com/fh/files/blogs/google_fog_of_war_research_report.pdf">KRYMSKYBRIDGE</a>, which is linked to a Russian consulting firm that works with the Russian government. Approximately 40% of activity was linked to actors associated with Russian state sponsored entities <a href="https://blog.google/threat-analysis-group/prigozhin-interests-and-russian-information-operations/">formerly controlled</a> by the late Russian oligarch <a href="https://cloud.google.com/blog/topics/threat-intelligence/io-campaigns-russian-prigozhin-persist?e=48754805">Yevgeny Prigozhin</a>. We also observed usage by actors tracked publicly as Doppelganger. </p>
<p>The majority of Russian IO actor usage was related to general research tasks, ranging from the Russia-Ukraine war to details about various tools and online services. Russian IO actors also used Gemini for content creation, rewriting article titles and planning social media campaigns. Translation to and from Russian was also a common task. </p>
<p>Russian IO actors focused on the generative AI landscape, which may indicate an interest in developing native capabilities in AI on infrastructure they control. They researched tools that can be used to create an online AI chatbot and developer tools for interacting with LLMs. One Russian IO actor used Gemini to suggest options for textual content analysis. </p>
<p>Pro-Russia IO actors have used AI in their influence campaigns in the past. In 2024, the actor known as CopyCop likely used LLMs to generate content, and some stories on their sites <a href="https://go.recordedfuture.com/hubfs/reports/cta-2024-0509.pdf">included metadata</a> indicating an LLM was prompted to rewrite articles from genuine news sources with a particular political perspective or tone. CopyCop&rsquo;s inauthentic news sites pose as US- and Europe-based news outlets and post Kremlin-aligned views on Western policy, the war in Ukraine, and domestic politics in the US and Europe.</p>
<p><strong>At a Glance: Russia-Linked IO Actors Using Gemini</strong></p>
<ul>
<li><strong>Four Russia-linked IO groups</strong> observed using Gemini</li>
<li><strong>Example use cases:</strong> 
<ul>
<li>
<ul>
<li>General research
<ul>
<li>
<ul>
<li>Research into the Russia-Ukraine war </li>
<li>Explain subscription plans and API details for online services</li>
<li>Research on different generative AI platforms, software, and systems for interacting with LLMs </li>
<li>Research on tools and methods for creating an online chatbot </li>
<li>Research tools for content analysis  </li>
</ul>
</li>
</ul>
</li>
<li>Translation - content in / out of native language
<ul>
<li>
<ul>
<li>Translate technical and business terminology into Russian </li>
<li>Translate text to/from Russian</li>
</ul>
</li>
</ul>
</li>
<li>Content creation - text 
<ul>
<li>
<ul>
<li>Draft a proposal for a social media agency </li>
<li>Rewrite article titles to garner more attention </li>
</ul>
</li>
</ul>
</li>
<li>Plan and strategize campaigns 
<ul>
<li>
<ul>
<li>Develop content strategy for different social media platforms and regions  </li>
<li>Brainstorm ideas for a PR campaign and accompanying visual designs</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="building-ai-safely-and-responsibly">Building AI Safely and Responsibly </h2>
<p>We believe our approach to AI must be both bold and responsible. To us, that means developing AI in a way that maximizes the positive benefits to society while addressing the challenges. Guided by our <a href="https://ai.google/responsibility/responsible-ai-practices/">AI Principles</a>, Google designs AI systems with robust security measures and strong safety guardrails, and we continuously test the security and safety of our models to improve them. Our <a href="https://gemini.google/policy-guidelines/?hl=en">policy guidelines</a> and prohibited use <a href="https://policies.google.com/terms/generative-ai/use-policy">policies</a> prioritize safety and responsible use of Google&rsquo;s generative AI tools. Google&rsquo;s <a href="https://transparency.google/our-approach/our-policy-process/">policy development process</a> includes identifying emerging trends, thinking end-to-end, and designing for safety. We continuously enhance safeguards in our products to offer scaled protections to users across the globe.  </p>
<p>At Google, we leverage threat intelligence to disrupt adversary operations. We investigate abuse of our products, services, users and platforms, including malicious cyber activities by government-backed threat actors, and work with law enforcement when appropriate. Moreover, our learnings from countering malicious activities are fed back into our product development to improve safety and security for our AI models. Google DeepMind also develops threat models for generative AI to identify potential vulnerabilities, and creates new evaluation and training techniques to address misuse caused by them. In conjunction with this research, DeepMind has shared how they&rsquo;re actively deploying defenses within AI systems along with measurement and monitoring tools, one of which is a <a href="https://security.googleblog.com/2025/01/how-we-estimate-risk-from-prompt.html?m=1">robust evaluation framework</a> used to automatically red team an AI system&rsquo;s vulnerability to indirect prompt injection attacks. Our AI development and Trust &amp; Safety teams also work closely with our threat intelligence, security, and modelling teams to stem misuse.</p>
<p>The potential of AI, especially generative AI, is immense. As innovation moves forward, the industry needs security standards for building and deploying AI responsibly. That&rsquo;s why we introduced the <a href="https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/">Secure AI Framework (SAIF)</a>, a conceptual framework to secure AI systems. We&rsquo;ve shared a comprehensive <a href="https://ai.google.dev/">toolkit for developers</a> with <a href="https://ai.google.dev/responsible">resources and guidance</a> for designing, building, and evaluating AI models responsibly. We&rsquo;ve also shared best practices for <a href="https://ai.google.dev/responsible/docs/safeguards">implementing safeguards</a>, <a href="https://ai.google.dev/responsible/docs/evaluation#red-teaming">evaluating model safety</a>, and <a href="https://blog.google/technology/safety-security/googles-ai-red-team-the-ethical-hackers-making-ai-safer/">red teaming</a> to test and secure AI systems. </p>
<h2 id="about-the-authors">About the Authors</h2>
<p>Google Threat Intelligence Group brings together the Mandiant Intelligence and Threat Analysis Group (TAG) teams, and focuses on identifying, analyzing, mitigating, and eliminating entire classes of cyber threats against Alphabet, our users, and our customers. Our work includes countering threats from government-backed attackers, targeted 0-day exploits, coordinated information operations (IO), and serious cyber crime networks. We apply our intelligence to improve Google&rsquo;s defenses and protect our users and customers.</p>
<h4 id="source"><a href="https://cloud.google.com/blog/topics/threat-intelligence/adversarial-misuse-generative-ai/">Source</a></h4>

			</div>
		</article>
	</main>
<aside>
	<div>
		<div>
			<h3>LATEST POSTS</h3>
		</div>
		<div>
			<ul>
				
				<li><a href="/posts/2025-03-22-thanks-for-hackaday-europe/">Thanks for Hackaday Europe</a></li>
				
				<li><a href="/posts/2025-03-22-indiana-health-systems-unite-to-help-sm/">Indiana health systems unite to help smaller providers tackle cybersecurity</a></li>
				
				<li><a href="/posts/2025-03-22-cve-2025-2577---bitspecter-suite-for-wo/">CVE-2025-2577 - Bitspecter Suite for WordPress Stored XSS</a></li>
				
				<li><a href="/posts/2025-03-22-cve-2025-1971---wordpress-export-and-im/">CVE-2025-1971 - WordPress Export and Import Users and Customers Plugin PHP Object Injection Vulnerability</a></li>
				
				<li><a href="/posts/2025-03-22-cve-2025-1972---wordpress-export-import/">CVE-2025-1972 - WordPress Export Import Users and Customers Plugin Remote File Deletion Vulnerability</a></li>
				
			</ul>
		</div>
	</div>
</aside>


	<footer>
	<p>&copy; 2025 <a href="https://ghariib.ir/"><b>Alireza Gharib. All right reserved</b></a>.
	<a href="https://github.com/Gharib110"><b>Github</b></a>.
	</p>
</footer>

</body>
</html>
