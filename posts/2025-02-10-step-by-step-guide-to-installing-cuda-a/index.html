<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<style type=text/css>body{font-family:monospace;}</style>
	<title>Step-by-Step Guide to Installing CUDA and cuDNN for GPU Acceleration</title>
	
	
	<link rel="stylesheet" href="/css/style.css">
	
	
</head>
<body>
	<header>
	==========================<br>
	== <a href="https://ghariib.ir/">Gharib Personal Blog</a> ==<br>
	==========================
	<div style="float: right;">A Techi Personal Blog</div><br>
	<p>
	<nav>
			<a href="/"><b>Start</b></a>.
			
			
			<a href="/posts/"><b>Posts</b></a>.
			
			<a href="/categories/"><b>Categories</b></a>.
			
			<a href="/tags/"><b>Tags</b></a>.
			
	</nav>
	</p>
	
</header>

	
	<main>
		<article>
			<h1>Step-by-Step Guide to Installing CUDA and cuDNN for GPU Acceleration</h1>
			<b><time>10.02.2025 19:16</time></b>
		       

			<div>
				<h1 id="step-by-step-guide-to-installing-cuda-and-cudnn-for-gpu-acceleration">Step-by-Step Guide to Installing CUDA and cuDNN for GPU Acceleration</h1>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>GPU acceleration has revolutionized deep learning, scientific computing, and machine learning, enhancing performance over traditional CPU computations.</p>
<p>This guide shows you how to install CUDA and cuDNN for GPU, enabling tasks like neural network training, large-scale data analysis, and complex simulations.</p>
<p>We’ll discuss compatibility considerations, troubleshooting advice, and best practices for ensuring a smooth <strong>GPU setup for CUDA</strong>.</p>
<p>By adhering to this guide, you’ll use the full capabilities of GPU for faster and more efficient computational processes.</p>
<h2 id="prerequisites"><a href="#prerequisites">Prerequisites</a><a href="#prerequisites"></a></h2>
<p>Having a solid grounding in some concepts will improve your understanding of this guide:</p>
<ul>
<li><strong>Basic Computer Proficiency:</strong> Ability to navigate your OS (whether it’s Windows or Linux) and complete basic tasks related to file management.</li>
<li><strong>Familiarity with Command-Line Tools</strong></li>
<li><strong>Understanding of GPUs:</strong> A general understanding of GPUs and their advantages over CPUs, particularly regarding parallel processing and applications in machine learning.</li>
<li><strong>Basic Understanding of Machine Learning/Deep Learning:</strong> Familiarity with popular frameworks such as <a href="/community/tutorials/how-to-install-tensorflow-on-ubuntu-20-04">TensorFlow</a> or <a href="/community/tutorials/pytorch-101-advanced">PyTorch</a> and their utilization of GPUs to speed model training.</li>
<li><strong>Programming Fundamentals:</strong> Some experience with languages like Python since the guide incorporates code snippets to verify installation and framework configuration.</li>
<li><strong>Understanding of System Architecture:</strong> Awareness of whether your system is 64-bit, along with understanding the difference between drivers, libraries, and software dependencies.</li>
<li><strong>Understanding of Environment Variables:</strong> A basic understanding of how to set environment variables (for instance, <a href="/community/tutorials/how-to-use-variables-in-python-3">PATH and LD_LIBRARY_PATH</a>) is important to configure the software.</li>
</ul>
<h2 id="what-are-cuda-and-cudnn"><a href="#what-are-cuda-and-cudnn">What are CUDA and cuDNN</a><a href="#what-are-cuda-and-cudnn"></a></h2>
<p><strong>CUDA</strong> (<a href="/community/tutorials/intro-to-cuda">Compute Unified Device Architecture</a>) is a groundbreaking platform for parallel computing created by NVIDIA. It provides programmers and researchers direct access to NVIDIA GPUs’ virtual instruction set. CUDA improves the efficiency of complex operations such as training AI models, processing large datasets, and conducting scientific simulations.</p>
<p><strong>cuDNN</strong> (CUDA Deep Neural Network library) is a specialized, GPU-accelerated library that provides essential building blocks for deep neural networks. It’s designed to deliver high-performance components for convolutional neural networks, recurrent neural networks (RNNs), and other complex deep learning algorithms. By implementing <strong>cuDNN</strong>, frameworks such as TensorFlow and PyTorch can take advantage of optimized GPU performance.</p>
<p>In short, <strong>NVIDIA’s CUDA installation</strong> lays the groundwork for GPU computing, whereas <strong>cuDNN provides</strong> targeted resources for deep learning. This combination enables remarkable GPU acceleration for tasks that a traditional CPU could otherwise require days or weeks to complete.</p>
<h2 id="system-requirements-and-preparations"><a href="#system-requirements-and-preparations">System Requirements and Preparations</a><a href="#system-requirements-and-preparations"></a></h2>
<p>Before you start the <strong>NVIDIA CUDA installation</strong> or <strong>cuDNN installation steps</strong>, please ensure your system fulfills the following requirements:</p>
<ul>
<li><strong>CUDA-Enabled NVIDIA GPU:</strong> Verify if your GPU is included in <a href="https://developer.nvidia.com/cuda-gpus">NVIDIA’s list of CUDA-enabled GPUs</a>. While most recent NVIDIA GPUs support CUDA, it’s wise to check.</li>
<li>If using Linux, launch a terminal and execute <code>lspci | grep—i nvidia</code> to identify your GPU. Then, check its CUDA compatibility on NVIDIA’s official site.</li>
<li><strong>Sufficient Disk Space:</strong> Setting up CUDA, cuDNN, and the necessary drivers may require several gigabytes of storage. You must have a minimum of 5–10 GB of free disk space available.</li>
<li><strong>Administrative Privileges:</strong> Installation on Windows and Ubuntu requires admin or sudo rights.</li>
<li><strong>NVIDIA GPU Drivers:</strong> You need to install the latest drivers on your machine. While this can often be included in the CUDA installation process, it is advisable to verify that you have the latest drivers directly from NVIDIA’s website.</li>
</ul>
<p>To get deeper into the GPU capabilities, explore our article related to <a href="/community/tutorials/intro-to-cuda">Nvidia CUDA</a> with H100.</p>
<h2 id="installing-cuda-and-cudnn-on-windows"><a href="#installing-cuda-and-cudnn-on-windows">Installing CUDA and cuDNN on Windows</a><a href="#installing-cuda-and-cudnn-on-windows"></a></h2>
<p>This section provides a detailed guide on installing CUDA and cuDNN on a Windows system.</p>
<p>
<figure>
  <img src="https://doimages.nyc3.cdn.digitaloceanspaces.com/008ArticleImages/cuda_cudnn_windows.png" alt="Install CUDA and cuDNN on Windows" />
</figure>


</p>
<h3 id="step-1-verify-gpu-compatibility"><a href="#step-1-verify-gpu-compatibility">Step 1: Verify GPU Compatibility</a><a href="#step-1-verify-gpu-compatibility"></a></h3>
<p>To determine your GPU model and check if it is compatible with CUDA, right-click on the <strong>Start Menu</strong>, choose <strong>Device Manager</strong>, and then expand the <strong>Display Adapters</strong> section to locate your NVIDIA GPU. After finding it, head over to the <a href="https://developer.nvidia.com/cuda-gpus"><strong>NVIDIA CUDA-Enabled GPU List</strong></a> to verify whether the specific GPU model supports CUDA for GPU acceleration.</p>
<h3 id="step-2-install-nvidia-gpu-drivers"><a href="#step-2-install-nvidia-gpu-drivers">Step 2: Install NVIDIA GPU Drivers</a><a href="#step-2-install-nvidia-gpu-drivers"></a></h3>
<p>To download and set up the latest NVIDIA drivers, go to the <a href="https://www.nvidia.com/Download/index.aspx"><strong>NVIDIA Driver Downloads</strong></a> section and choose the correct driver for your GPU and Windows version. Then, execute the downloaded installer and follow the instructions on your screen. After you’ve installed the driver, make sure to restart your system to apply the changes.</p>
<h3 id="step-3-install-the-cuda-toolkit"><a href="#step-3-install-the-cuda-toolkit">Step 3: Install the CUDA Toolkit</a><a href="#step-3-install-the-cuda-toolkit"></a></h3>
<p>To start, go to the <a href="https://developer.nvidia.com/cuda-toolkit-archive"><strong>CUDA Toolkit Archive</strong></a> and select the version that aligns with your project needs. If you’re using guidelines like <strong>“<strong>How to install CUDA and cuDNN on GPU 2021</strong>,”</strong> it might be wise to choose a version from that timeframe to maintain compatibility with previous frameworks.</p>
<p>You will choose your operating system, such as Windows, with the architecture, typically x86_64. You will also indicate your Windows version, whether Windows 10 or 11.</p>
<p>After selection, you can download either the local .exe installer or the network installer. Next, execute the downloaded installer and proceed through the installation prompts. During this process, ensure you choose all essential components, such as the <strong>CUDA Toolkit</strong>, sample projects, and documentation, to set up a comprehensive development environment.</p>
<p>The installer will copy the necessary files to the default directory: <code>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\vX.X</code>. In this case, <em>X.X</em> represents the specific version of CUDA you are installing.</p>
<p>Finally, while the installer generally manages environment variables automatically, it’s important to check them. Open the command prompt and execute the following commands to confirm that the <code>CUDA\_PATH</code> and <code>PATH</code> variables point to the correct CUDA directories:</p>
<pre tabindex="0"><code>*echo %CUDA\_PATH%*    
*echo %PATH%*
</code></pre><h3 id="step-4-download-and-install-cudnn-on-windows"><a href="#step-4-download-and-install-cudnn-on-windows">Step 4: Download and Install cuDNN on Windows</a><a href="#step-4-download-and-install-cudnn-on-windows"></a></h3>
<ul>
<li><strong>Register as an NVIDIA Developer:</strong> To gain access, you need to set up an account on the NVIDIA Developer website to access <a href="https://developer.nvidia.com/cudnn-downloads">cuDNN downloads</a>.</li>
<li><strong>Check Compatibility:</strong> It’s important to ensure the cuDNN version aligns with your installed CUDA version. If you have, for example, CUDA 11.8, search specifically for <strong>cuDNN 8</strong> builds that indicate they support CUDA 11.8.</li>
</ul>
<h4 id="using-the-installer">Using the Installer</h4>
<p>Download the cuDNN installer for Windows and run it, following the on-screen prompts. During installation, choose either Express or Custom installation based on your preference.</p>
<h4 id="manual-installation">Manual Installation</h4>
<p>Unzip the downloaded file for manual installation and place it in a temporary folder. Then copy:</p>
<pre tabindex="0"><code>bin\\cudnn\*.dll to C:\\Program Files\\NVIDIA\\CUDNN\\vx.x\\bin,
include\\cudnn\*.h to C:\\Program Files\\NVIDIA\\CUDNN\\vx.x\\include,
lib\\x64\\cudnn\*.lib to C:\\Program Files\\NVIDIA\\CUDNN\\vx.x\\lib.
</code></pre><p>Replace ‘x.x’ with your version number.</p>
<p>Lastly, update your system’s PATH variable by adding <code>C:\\Program Files\\NVIDIA\\CUDNN\\vx.x\\bin</code> to ensure you can access cuDNN executables properly.</p>
<h4 id="verification">Verification</h4>
<p>Check the folder contents to verify that the cuDNN files are correctly placed. You should find a <code>cudnn64_x.dll</code> file in the bin directory and <code>.h</code> header files in the include directory.</p>
<h3 id="step-5-environment-variables-on-windows"><a href="#step-5-environment-variables-on-windows">Step 5: Environment Variables on Windows</a><a href="#step-5-environment-variables-on-windows"></a></h3>
<p>Although the CUDA installer typically manages environment variables automatically, it is wise to verify that all configurations are accurate:</p>
<ol>
<li>
<p><strong>Open System Properties</strong></p>
<ul>
<li>Right-click on <strong>This PC</strong> (or <strong>Computer</strong>) and choose <strong>Properties</strong>.</li>
<li>Go to <strong>Advanced System Settings</strong>, and then click on <strong>Environment Variables</strong>.</li>
</ul>
</li>
<li>
<p><strong>Check CUDA_PATH</strong></p>
<ul>
<li>In the section labeled <strong>System variables</strong>, search for CUDA_PATH.</li>
<li>It should direct to: <code>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\vX.X</code>. Replace X.X with the version of CUDA that is installed (e.g., v11.8).</li>
</ul>
</li>
<li>
<p><strong>Path Variable</strong></p>
<p>In the same section, under <strong>System variables</strong>, find and select Path.</p>
<p>Check that the following directory is included: <code>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\vX.X\\bin</code>. You may also find: <code>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\vX.X\\libnvvp</code>. If it’s not there, add it manually to help the system locate CUDA executables.</p>
</li>
<li>
<p><strong>Add cuDNN If Needed</strong></p>
<p>Generally, copying cuDNN files into the appropriate CUDA folders (bin, include, lib) is sufficient. If you keep cuDNN in a different location, add that folder path to your Path variable so Windows can find the cuDNN libraries.</p>
</li>
</ol>
<h2 id="installing-cuda-on-ubuntu"><a href="#installing-cuda-on-ubuntu">Installing CUDA on Ubuntu</a><a href="#installing-cuda-on-ubuntu"></a></h2>
<p>This section shows how to install the CUDA Toolkit on your Ubuntu system. It covers repository setup, GPG key verification, and package installation.</p>
<p>
<figure>
  <img src="https://doimages.nyc3.cdn.digitaloceanspaces.com/008ArticleImages/cuda_ubuntu.png" alt="Install CUDA on Ubuntu" />
</figure>


</p>
<h3 id="step-1-install-required-packages"><a href="#step-1-install-required-packages">Step 1: Install Required Packages</a><a href="#step-1-install-required-packages"></a></h3>
<p>Ensure that <code>curl</code> is installed on your system:</p>
<pre tabindex="0"><code>sudo apt update
sudo apt install curl
</code></pre><h3 id="step-2-install-nvidia-drivers"><a href="#step-2-install-nvidia-drivers">Step 2: Install NVIDIA Drivers</a><a href="#step-2-install-nvidia-drivers"></a></h3>
<p>Before installing CUDA, it’s essential to have the appriproriate NVIDIA drivers intalled—to do so:</p>
<pre tabindex="0"><code>sudo ubuntu-drivers autoinstall
</code></pre><p>Then, make sure to reboot your system after driver installation</p>
<pre tabindex="0"><code>sudo reboot
</code></pre><h3 id="step-3-add-the-nvidia-gpg-key"><a href="#step-3-add-the-nvidia-gpg-key">Step 3: Add the NVIDIA GPG Key</a><a href="#step-3-add-the-nvidia-gpg-key"></a></h3>
<p>To ensure the authenticity of packages from the NVIDIA repository, add the NVIDIA GPG key</p>
<pre tabindex="0"><code>curl -fsSL https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/3bf863cc.pub | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-cuda-keyring.gpg
</code></pre><p>The <code>curl -fsSL https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/3bf863cc.pub</code> command uses curl to retrieve the public key from the designated URL. The flags included are:</p>
<ul>
<li>-f: Silently fail in the event of server errors.</li>
<li>-s: Operate in silent mode (no progress indicators or error notifications).</li>
<li>-S: Show error notifications when -s is used.</li>
<li>-L: Follow redirects.</li>
</ul>
<p>The <code>| sudo gpg --dearmor -o /usr/share/keyrings/nvidia-cuda-keyring.gpg</code> segment takes the output from the curl directive into <code>gpg</code>, which converts the key from ASCII to binary format and saves it in the chosen location. The sudo command guarantees you have the required permissions.</p>
<p>The resulting binary key is stored in <code>/usr/share/keyrings/nvidia-cuda-keyring.gpg</code>, allowing the Ubuntu system to verify the package integrity from NVIDIA’s CUDA repository.</p>
<h3 id="step-4-add-the-cuda-repository"><a href="#step-4-add-the-cuda-repository">Step 4: Add the CUDA Repository</a><a href="#step-4-add-the-cuda-repository"></a></h3>
<p>Incorporate the CUDA repository that corresponds to your Ubuntu version. For example, for Ubuntu 22.04 you can run:</p>
<pre tabindex="0"><code>echo &#34;deb [signed-by=/usr/share/keyrings/nvidia-cuda-keyring.gpg] https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/ /&#34; | sudo tee /etc/apt/sources.list.d/cuda-repository.list
</code></pre><ul>
<li><code>echo &quot;deb \[signed-by=/usr/share/keyrings/nvidia-cuda-keyring.gpg\] https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86\_64/</code>: This command sets up a line that indicates the repository URL and the keyring for package signing.</li>
<li><code>| *sudo tee /etc/apt/sources.list.d/cuda-repository.list</code>: This command sends the output from <em>echo</em> to <em>tee</em>, which writes it into the specified file or creates it if it doesn’t exist. The <em>sudo</em> ensures you have permission to alter system files.</li>
</ul>
<p>There are many repository tags for different Ubuntu versions and you can adjust the URL as required if you use a different Ubuntu version (e.g., ubuntu2004 or ubuntu1804).</p>
<h3 id="step-5-update-the-package-repository"><a href="#step-5-update-the-package-repository">Step 5: Update the Package Repository</a><a href="#step-5-update-the-package-repository"></a></h3>
<p>Now, you can update your package list to include the new repository:</p>
<pre tabindex="0"><code>sudo apt update
</code></pre><p>This guarantees that Ubuntu can recognize and fetch packages from the NVIDIA CUDA repository.</p>
<h3 id="step-6-install-the-cuda-toolkit"><a href="#step-6-install-the-cuda-toolkit">Step 6: Install the CUDA Toolkit</a><a href="#step-6-install-the-cuda-toolkit"></a></h3>
<p>Install the CUDA Toolkit with the following command:</p>
<pre tabindex="0"><code>sudo apt install cuda
</code></pre><p>This command will install all the CUDA components necessary for GPU acceleration, including compilers and libraries. It’s important to note that this will install the latest version of CUDA. If you’re looking for a particular version, you’ll need to specify it, such as <code>sudo apt install cuda-11-814</code>.</p>
<h3 id="step-7-set-up-environment-variables"><a href="#step-7-set-up-environment-variables">Step 7: Set Up Environment Variables</a><a href="#step-7-set-up-environment-variables"></a></h3>
<p>To ensure CUDA is available whenever you open a new terminal session, add these lines to your ~/.bashrc file:</p>
<pre tabindex="0"><code>export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
</code></pre><p>The first line places <code>/usr/local/cuda/bin</code> at the beginning of your PATH, making the nvcc compiler accessible.</p>
<p>The second line appends <code>/usr/local/cuda/lib64</code> to your LD_LIBRARY_PATH, assisting the system in locating CUDA libraries. The specific paths will depend on the installed version of CUDA.</p>
<p><strong>Note:</strong> The <code>.bashrc</code> file is a hidden shell script found within your home directory that is executed each time you initiate a new interactive terminal session within the Bash shell. It includes commands for setting up your environment, like environment variables, aliases, and functions, which customize and manage your shell behavior each time you launch a terminal.</p>
<p>Finally, reload your <code>.bashrc</code> so the new enviornment variables take effect right away:</p>
<pre tabindex="0"><code>source ~/.bashrc
</code></pre><h3 id="step-8-verification"><a href="#step-8-verification">Step 8: Verification</a><a href="#step-8-verification"></a></h3>
<p>Verify that CUDA was installed successfully:</p>
<pre tabindex="0"><code>nvcc --version
</code></pre><p>If CUDA is correctly installed, this command will display the installed CUDA version.</p>
<p>By completing these steps, you’ve successfully installed CUDA on Ubuntu, set up the essential environment variables, and prepared your system for GPU-accelerated applications.</p>
<h2 id="installing-cudnn-on-ubuntu"><a href="#installing-cudnn-on-ubuntu">Installing cuDNN on Ubuntu</a><a href="#installing-cudnn-on-ubuntu"></a></h2>
<p>Thanks to NVIDIA’s package manager support, installing cuDNN on Linux has been simplified. Here is a brief guide that outlines both the recommended package manager method (for Ubuntu/Debian systems) and the manual installation process in case packages are unavailable for your specific distribution.</p>
<p><strong>Note:</strong> If the package manager is available for your Linux distribution, it tends to be the easiest and most manageable option. Also, when performing a manual installation, pay careful attention to file paths, versions, and permissions to ensure that cuDNN works flawlessly with your existing CUDA configuration.</p>
<h3 id="step-1-download-cudnn"><a href="#step-1-download-cudnn">Step 1: Download cuDNN</a><a href="#step-1-download-cudnn"></a></h3>
<ol>
<li>Go to the official <a href="https://developer.nvidia.com/cudnn">NVIDIA cuDNN download page</a>.</li>
<li>Sign in to your NVIDIA Developer account (or create one if you don’t have it).</li>
<li>Choose the <strong>cuDNN version</strong> that corresponds with your installed <strong>CUDA</strong> version.</li>
<li>Download the <strong>Linux package</strong> (usually provided as a .tar.xz file) if you intend to install it manually, or take note of the version strings if you prefer to use your package manager.</li>
</ol>
<h3 id="step-2-install-cudnn"><a href="#step-2-install-cudnn">Step 2: Install cuDNN</a><a href="#step-2-install-cudnn"></a></h3>
<h4 id="option-a-using-the-package-manager">Option A: Using the Package Manager</h4>
<p>For Ubuntu or Debian-based distributions, NVIDIA recommends installing cuDNN via apt:</p>
<pre tabindex="0"><code>sudo apt-get install libcudnn8=8.x.x.x-1+cudaX.X
sudo apt-get install libcudnn8-dev=8.x.x.x-1+cudaX.X
</code></pre><ul>
<li>Swap <strong>8.x.x.x</strong> with the actual cuDNN version you have downloaded.</li>
<li>Replace <strong>X.X</strong> to match your installed CUDA version (for example, <em>cuda11.8</em>).</li>
</ul>
<h4 id="option-b-manual-installation">Option B: Manual Installation</h4>
<p>If the package manager is unavailable or not supported in your distribution, first extract the archive using this command:</p>
<pre tabindex="0"><code>tar -xf cudnn-linux-x86_64-x.x.x.x_cudaX.X-archive.tar.xz
</code></pre><p>Update <code>x.x.x.x</code> (cuDNN version) and <code>X.X</code> (CUDA version) to correspond with the versions stated in your archive’s name.</p>
<p>Then, copy the cuDNN files using the following command:</p>
<pre tabindex="0"><code>sudo cp cudnn-*-archive/include/cudnn*.h /usr/local/cuda/include/
sudo cp -P cudnn-*-archive/lib/libcudnn* /usr/local/cuda/lib64/
sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*
</code></pre><p>This series of instructions copy the cuDNN header files (<code>cudnn\*.h</code>) to the CUDA <em>include</em> folder and copy the cuDNN library files (<code>libcudnn\</code>) to the CUDA library folder. By using the <code>\-P</code> option, any symbolic links will be maintained during this copy. <code>chmod a+r</code> grants read permissions to all users for these files, thereby ensuring they are accessible across the system.</p>
<h3 id="step-3-update-the-shared-library-cache"><a href="#step-3-update-the-shared-library-cache">Step 3: Update the Shared Library Cache</a><a href="#step-3-update-the-shared-library-cache"></a></h3>
<p>Regardless of whether you used the package manager for installation or manually copied the files, it’s important to refresh the library cache of your system:</p>
<pre tabindex="0"><code>sudo ldconfig
</code></pre><p>This step ensures that your operating system recognizes the newly added cuDNN libraries.</p>
<h3 id="step-4-verify-the-installation"><a href="#step-4-verify-the-installation">Step 4: Verify the Installation</a><a href="#step-4-verify-the-installation"></a></h3>
<p>To verify if cuDNN has been installed correctly, you can check the version details in <code>cudnn.h</code>:</p>
<pre tabindex="0"><code>cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2
</code></pre><p>This command will display the cuDNN version installed on your system by extracting specific lines from the <code>cudnn.h</code> header file. The component grep <code>CUDNN_MAJOR -A 2</code> narrows the output to display the major version number alongside the subsequent two lines, usually indicating the minor and patch version numbers.</p>
<p>If the installed cuDNN version is 8.9.2, the executed command may yield:</p>
<pre tabindex="0"><code>#define CUDNN_MAJOR 8
#define CUDNN_MINOR 9
#define CUDNN_PATCHLEVEL 2
</code></pre><h3 id="step-5-update-enviornment-variables"><a href="#step-5-update-enviornment-variables">Step 5: Update Enviornment Variables</a><a href="#step-5-update-enviornment-variables"></a></h3>
<p>Finally, add the CUDA binary and library directories to your <code>PATH</code> and <code>LD_LIBRARY_PATH</code> so your system can locate cuDNN and CUDA files.</p>
<p>First, edit (or create) the <code>~/.bashrc</code> file:</p>
<pre tabindex="0"><code>export PATH=/usr/local/cuda/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
</code></pre><p>Then, apply the changes in the current shell session:</p>
<pre tabindex="0"><code>source ~/.bashrc
</code></pre><h2 id="version-compatibility-and-framework-integration"><a href="#version-compatibility-and-framework-integration">Version Compatibility and Framework Integration</a><a href="#version-compatibility-and-framework-integration"></a></h2>
<p>Various deep learning frameworks require specific CUDA and cuDNN versions. Below is a general guideline:</p>
<p><strong>Framework</strong></p>
<p><strong>Supported CUDA Versions</strong></p>
<p><strong>Supported cuDNN Versions</strong></p>
<p><strong>Notes</strong></p>
<p>Tensorflow</p>
<p>11.2 - 12.2</p>
<p>8.1+</p>
<p>TensorFlow 2.15 is compatible with CUDA 12.2. Prior versions may require specific CUDA versions.</p>
<p>PyTorch</p>
<p>11.3 - 12.1</p>
<p>8.3.2+</p>
<p>PyTorch 2.1 is compatible with CUDA versions 11.8 and 12.1. The exact versions will vary based on the PyTorch release.</p>
<p>MXNet</p>
<p>10.1 - 11.7</p>
<p>7.6.5 - 8.5.0</p>
<p>MXNet 1.9.1 supports up to CUDA 11.7 and cuDNN 8.5.0.</p>
<p>Caffee</p>
<p>10.0 - 11.x</p>
<p>7.6.5 - 8.x</p>
<p>Caffe typically requires manual compilation. It is advisable to verify specific version requirements.</p>
<p>It is essential to consistently refer to the official documentation for each framework, as compatibility may change with subsequent releases.</p>
<h3 id="additional-notes"><a href="#additional-notes">Additional Notes</a><a href="#additional-notes"></a></h3>
<ul>
<li>The latest version of TensorFlow (version 2.16.1) has simplified the installation of the CUDA library on Linux with pip.</li>
<li>PyTorch binaries come pre-packaged with specific versions of CUDA and cuDNN…</li>
<li>MXNet requires accurate matching of the CUDA and cuDNN versions.</li>
<li>Installing JAX with CUDA and cuDNN support can be complex and often demands specific combinations of versions.</li>
</ul>
<h2 id="using-cuda-and-cudnn-with-popular-frameworks"><a href="#using-cuda-and-cudnn-with-popular-frameworks">Using CUDA and cuDNN with Popular Frameworks</a><a href="#using-cuda-and-cudnn-with-popular-frameworks"></a></h2>
<p>Modern deep learning tools work great with CUDA and cuDNN, providing significant speed improvements on systems equipped with GPUs. Here’s a quick rundown on setting up TensorFlow, PyTorch, and other popular libraries to get the most out of GPU acceleration.</p>
<h3 id="tensorflow-gpu-setup"><a href="#tensorflow-gpu-setup">Tensorflow GPU Setup</a><a href="#tensorflow-gpu-setup"></a></h3>
<h4 id="install-tensorflow-with-gpu-support">Install TensorFlow with GPU Support</h4>
<pre tabindex="0"><code>pip install tensorflow[and-cuda]
</code></pre><p>This command installs TensorFlow along with necessary CUDA dependencies. For Windows users, GPU support is generally enabled through <strong>WSL2(Windows Subsystem for Linux 2)</strong> or via the <strong>TensorFlow-DirectML-Plugin</strong>.</p>
<h4 id="verify-gpu-recognition">Verify GPU Recognition</h4>
<pre tabindex="0"><code>import tensorflow as tf
print(tf.config.list_physical_devices(&#39;GPU&#39;))
</code></pre><p>If TensorFlow detects your GPU, you should see at least one physical device mentioned in the results.</p>
<h4 id="common-tensorflow-errors">Common TensorFlow Errors**</h4>
<ul>
<li><strong>DLL load failed</strong>: This usually means cuDNN or CUDA isn’t set up properly in your system PATH.</li>
<li><strong>Could not load dynamic library</strong>: This often happens when there’s a mismatch between the installed CUDA/cuDNN versions and those expected by TensorFlow.</li>
</ul>
<h3 id="pytorch-cuda-configuration"><a href="#pytorch-cuda-configuration">PyTorch CUDA Configuration</a><a href="#pytorch-cuda-configuration"></a></h3>
<h4 id="install-pytorch">Install PyTorch</h4>
<pre tabindex="0"><code>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
</code></pre><p>This command will install the latest compatible versions of torch, torchvision, and torchaudio built for CUDA 12.1. You must make sure you have the appropriate CUDA 12.1 drivers installed on your system for optimal performance.</p>
<h4 id="check-gpu-availability">Check GPU Availability</h4>
<pre tabindex="0"><code>import torch
print(torch.cuda.is_available()) # Should return True if everything is correct
</code></pre><p>A <code>True</code> output means PyTorch can recognize your GPU.</p>
<h4 id="optimulti-gpu-setup">OptiMulti-GPU Setup</h4>
<p>If you have multiple GPUS, you can perform computations using <code>torch.nn.DataParallel</code> or <a href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html">DistributedDataParallel</a>. To see how many GPUs PyTorch identifies, run:</p>
<pre tabindex="0"><code>torch.cuda.device_count()
</code></pre><h3 id="other-frameworks-mxnet-caffee-etc"><a href="#other-frameworks-mxnet-caffee-etc">Other Frameworks (MXNet, Caffee, etc.)</a><a href="#other-frameworks-mxnet-caffee-etc"></a></h3>
<h4 id="mxnet">MXNet</h4>
<p>First, install the GPU version:</p>
<pre tabindex="0"><code>pip install mxnet-cu``x
</code></pre><p>The placeholder <code>cu11x</code> should be replaced with the actual version, suchc as <code>cu110</code> for CUDA 11.0 or <code>cu113</code> for CUDA 11.3</p>
<p>Next, check how many GPUs you have acces to</p>
<pre tabindex="0"><code>import mxnet as mx
print (mx.context.num_gpus())
</code></pre><p>If you see a non-zero result, that means MXNet can access your GPUs.</p>
<h4 id="caffee">Caffee</h4>
<ul>
<li>Usually, you’ll compile this from the source and set up your <strong>CUDA</strong> and <strong>cuDNN</strong> paths in the <em>Makefile.config</em> file.</li>
<li>Some users prefer to install Caffe via <strong>Conda</strong> but make sure your CUDA and cuDNN versions align with the library’s requirements.</li>
</ul>
<p>Following these steps, you can easily set up GPU acceleration for different deep learning frameworks, taking full advantage of CUDA and cuDNN for faster training and inference.</p>
<p>To learn about advanced PyTorch debugging and memory management, read our article on <a href="/community/tutorials/pytorch-memory-multi-gpu-debugging">PyTorch Memory and Multi-GPU Debugging</a>.</p>
<h2 id="installing-cudnn-with-python-wheels-via-pip"><a href="#installing-cudnn-with-python-wheels-via-pip">Installing cuDNN with Python Wheels via pip</a><a href="#installing-cudnn-with-python-wheels-via-pip"></a></h2>
<p>NVIDIA provides Python wheels for easy installation of cuDNN through pip, simplifying the integration process into Python projects. This method is particularly advantageous for those working with deep learning frameworks like TensorFlow and PyTorch.</p>
<h3 id="prerequisite"><a href="#prerequisite">Prerequisite</a><a href="#prerequisite"></a></h3>
<ul>
<li><strong>Python Environment:</strong> Make sure Python is installed on your system. To prevent conflicts, it’s recommended that you use a virtual environment for managing dependencies.</li>
<li><strong>CUDA Toolkit:</strong> Install the appropriate version of the CUDA Toolkit that is compatible with both your GPU and the cuDNN version you plan to use.</li>
</ul>
<h3 id="step-1-upgrade-pip-and-wheel"><a href="#step-1-upgrade-pip-and-wheel">Step 1: Upgrade pip and wheel</a><a href="#step-1-upgrade-pip-and-wheel"></a></h3>
<p>Before installing cuDNN, ensure that <code>pip</code> and wheel are updated to their latest versions:</p>
<pre tabindex="0"><code>python3 -m pip install --upgrade pip wheel
</code></pre><h3 id="step-2-installing-cudnn"><a href="#step-2-installing-cudnn">Step 2: Installing cuDNN</a><a href="#step-2-installing-cudnn"></a></h3>
<p>To install CUDA 12, use the following command:</p>
<pre tabindex="0"><code>python 3 -m pip install nvidia-cudnn-cu12
</code></pre><p>To install Cuda 11, use the following command:</p>
<pre tabindex="0"><code>python 3 -m pip install nvidia-cudnn-cu11
</code></pre><p>For a specific version of cuDNN (e.g. 9.x.y.z), you can specify the version number:</p>
<pre tabindex="0"><code>python3 -m pip install nvidia-cudnn-cu12==9.x.y.z
</code></pre><h2 id="troubleshooting-common-issues"><a href="#troubleshooting-common-issues">Troubleshooting Common Issues</a><a href="#troubleshooting-common-issues"></a></h2>
<p>This section outlines common issues encountered with CUDA and cuDNN and provides their causes along with respective solutions.</p>
<p>
<figure>
  <img src="https://doimages.nyc3.cdn.digitaloceanspaces.com/008ArticleImages/cuda_cudnn_issues.png" alt="How to resolve CUDA/cuDNN issues?" />
</figure>


</p>
<h3 id="cuda-driver-version-insufficiency"><a href="#cuda-driver-version-insufficiency">Cuda Driver Version Insufficiency</a><a href="#cuda-driver-version-insufficiency"></a></h3>
<ul>
<li><strong>Cause</strong>: The GPU driver in use is outdated compared to the version required for the CUDA Toolkit on your system.</li>
<li><strong>Solution</strong>: Update your driver to a version that is at least as recent as recommended for your CUDA version. Afterward, restart your system and attempt the operation again.</li>
</ul>
<h3 id="cudnn-library-not-found"><a href="#cudnn-library-not-found">cuDNN Library Not Found</a><a href="#cudnn-library-not-found"></a></h3>
<ul>
<li><strong>Cause</strong>: The cuDNN files might be incorrectly located, or your environment variables are not set up properly.</li>
<li><strong>Solution</strong>: Ensure that <code>cudnn64\_x.dll</code> (for Windows) or <code>libcudnn.so</code> (for Linux) is placed within the same directory as your CUDA installation. Also, verify that <code>LD\_LIBRARY\_PATH</code> or <code>PATH</code> includes the directory where these libraries reside.</li>
</ul>
<h3 id="multiple-cuda-versions-on-the-same-machine"><a href="#multiple-cuda-versions-on-the-same-machine">Multiple CUDA Versions on the Same Machine</a><a href="#multiple-cuda-versions-on-the-same-machine"></a></h3>
<p>You can install various CUDA versions (like 10.2 and 11.8) simultaneously, but be aware of the following:</p>
<ul>
<li><strong>Path issues</strong>: Only one version can take precedence in your environment <code>PATH</code>.</li>
<li><strong>Framework Configuration</strong>: Certain frameworks may default to the first <code>nvcc</code> they recognize.</li>
<li><strong>Recommendation</strong>: Use environment modules or containerization techniques (like Docker) to isolate different CUDA versions.</li>
</ul>
<h3 id="enviornment-variable-conflicts"><a href="#enviornment-variable-conflicts">Enviornment Variable Conflicts</a><a href="#enviornment-variable-conflicts"></a></h3>
<p>You might encounter library mismatch errors if your <code>PATH</code> or <code>LD_LIBRARY_PATH</code> points to an old or conflicting CUDA version. Always check that your environment variables correspond to the correct paths for the specific CUDA/cuDNN version you plan to use.</p>
<h2 id="faqs"><a href="#faqs">FAQs</a><a href="#faqs"></a></h2>
<h3 id="how-to-install-cuda-on-a-gpu"><a href="#how-to-install-cuda-on-a-gpu">How to install CUDA on a GPU?</a><a href="#how-to-install-cuda-on-a-gpu"></a></h3>
<p>Begin by downloading and installing the latest <strong>NVIDIA GPU driver</strong> suitable for your operating system. Next, head to NVIDIA’s official website to get the <strong>CUDA Toolkit</strong>, and proceed to run the installation. Don’t forget to restart the system once you have completed the installation.</p>
<h3 id="how-to-set-up-cuda-and-cudnn"><a href="#how-to-set-up-cuda-and-cudnn">How to set up CUDA and cuDNN?</a><a href="#how-to-set-up-cuda-and-cudnn"></a></h3>
<p>First, proceed with installing the <a href="https://developer.nvidia.com/cuda-toolkit">CUDA Toolkit</a> and downloading cuDNN from the <a href="https://developer.nvidia.com/">NVIDIA Developer portal</a>. Copy the cuDNN files into the CUDA directories (namely, bin, include, and lib) and adjust environment variables as required.</p>
<h3 id="can-i-use-cuda-on-my-gpu"><a href="#can-i-use-cuda-on-my-gpu">Can I use CUDA on my GPU?</a><a href="#can-i-use-cuda-on-my-gpu"></a></h3>
<p>As long as your GPU is an <strong>NVIDIA GPU</strong> that supports CUDA. You can verify this by referring to NVIDIA’s official list or inspecting your GPU’s product page details.</p>
<h3 id="how-to-install-cuda-118-and-cudnn"><a href="#how-to-install-cuda-11-8-and-cudnn">How to install CUDA 11.8 and cuDNN?</a><a href="#how-to-install-cuda-11-8-and-cudnn"></a></h3>
<p>Start with a compatible driver installation, then download the <a href="https://developer.nvidia.com/cuda-11-8-0-download-archive">CUDA 11.8 installer</a>. Afterward, download cuDNN version 8.x that aligns with CUDA 11.8, and make the cuDNN files placed in the correct directories.</p>
<h3 id="how-do-i-check-if-my-gpu-is-cuda-enabled"><a href="#how-do-i-check-if-my-gpu-is-cuda-enabled">How do I check if my GPU is CUDA enabled?</a><a href="#how-do-i-check-if-my-gpu-is-cuda-enabled"></a></h3>
<p>On a Windows system, you can check for an NVIDIA GPU in the <strong>Device Manager</strong>. For Linux users, execute the command: <code>lspci | grep \-i nvidia</code>. Finally, compare your GPU model with the specifications listed on NVIDIA’s website.</p>
<h3 id="is-cuda-a-gpu-driver"><a href="#is-cuda-a-gpu-driver">Is CUDA a GPU driver?</a><a href="#is-cuda-a-gpu-driver"></a></h3>
<p>No, CUDA itself is a <strong>parallel computing platform</strong>. You need to install the <strong>NVIDIA driver</strong> to communicate properly with GPU hardware.</p>
<h3 id="what-are-cuda-and-cudnn-used-for-in-ai-and-ml"><a href="#what-are-cuda-and-cudnn-used-for-in-ai-and-ml">What are CUDA and cuDNN used for in AI and ML?</a><a href="#what-are-cuda-and-cudnn-used-for-in-ai-and-ml"></a></h3>
<p>CUDA enables parallel computing tasks on the GPU, while cuDNN optimizes deep neural network processes, such as convolutions.</p>
<h3 id="how-do-i-check-if-my-gpu-supports-cuda"><a href="#how-do-i-check-if-my-gpu-supports-cuda">How do I check if my GPU supports CUDA?</a><a href="#how-do-i-check-if-my-gpu-supports-cuda"></a></h3>
<p>Find your GPU model on the <a href="https://developer.nvidia.com/">NVIDIA Developer site</a> or consult the list of CUDA-enabled GPUs. Generally, most modern NVIDIA GPUs support CUDA.</p>
<h3 id="what-is-the-difference-between-the-cuda-toolkit-and-cudnn"><a href="#what-is-the-difference-between-the-cuda-toolkit-and-cudnn">What is the difference between the CUDA Toolkit and cuDNN?</a><a href="#what-is-the-difference-between-the-cuda-toolkit-and-cudnn"></a></h3>
<p>The <strong>CUDA Toolkit provides</strong> essential libraries, a compiler, and tools necessary for general GPU computing, while <strong>cuDNN</strong> is a specialized library for deep neural network operations.</p>
<h3 id="how-do-i-resolve-the-cudnn-library-errors-that-were-not-found"><a href="#how-do-i-resolve-the-cudnn-library-errors-that-were-not-found">How do I resolve the cuDNN library errors that were not found?</a><a href="#how-do-i-resolve-the-cudnn-library-errors-that-were-not-found"></a></h3>
<p>Make sure that the cuDNN files (like .dll for Windows or .so for Linux) are correctly copied in the designated folders (e.g., /usr/local/cuda/lib64 on Linux), and verify that your environment variables point to those directories.</p>
<h3 id="can-i-install-multiple-versions-of-cuda-on-the-same-machine"><a href="#can-i-install-multiple-versions-of-cuda-on-the-same-machine">Can I install multiple versions of CUDA on the same machine?</a><a href="#can-i-install-multiple-versions-of-cuda-on-the-same-machine"></a></h3>
<p>Yes, it is possible. Each version should reside in its respective directory (for example, C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2, v11.8, etc.). You will need to update the PATH and other environmental variables when switching between versions.</p>
<h2 id="conclusion"><a href="#conclusion">Conclusion</a><a href="#conclusion"></a></h2>
<p>Installing CUDA and cuDNN is essential in unlocking the full capabilities of NVIDIA GPUs for tasks like deep learning, scientific simulations, and processing large datasets. By adhering to the detailed instructions provided in this guide, you’ll streamline the installation of CUDA cuDNN on both Windows and Ubuntu. This will result in accelerated model training, optimized data handling, and improved computational power.</p>
<p>When properly configured, with version compatibility checks and performance optimization, your GPU environment will be ready to support renowned frameworks such as TensorFlow, PyTorch, and MXNet. Whether you’re a beginner or have advanced knowledge, using CUDA and cuDNN can boost your efficiency. This will allow you to approach complex AI and machine learning challenges with improved speed and efficiency.</p>
<h2 id="references"><a href="#references">References</a><a href="#references"></a></h2>
<ul>
<li><a href="https://docs.nvidia.com/deeplearning/cudnn/backend/v9.0.0/installation/windows.html">Installing cuDNN on Windows</a></li>
<li><a href="https://pytorch.org/get-started/locally/">Getting Started with PyTorch</a></li>
<li><a href="https://www.tensorflow.org/install/pip">Install TensorFlow with pip</a></li>
<li><a href="https://docs.nvidia.com/deploy/cuda-compatibility/">CUDA Compatibility</a></li>
<li><a href="https://docs.nvidia.com/deeplearning/cudnn/installation/latest/windows.html">Installing cuDNN Backend on Windows</a></li>
<li><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/">CUDA Installation Guide for Microsoft Windows</a></li>
<li><a href="https://www.youtube.com/watch?v=Jt-d6zI99FY&amp;t=132s">How to Install or Update Nvidia Drivers on Windows 10 &amp; 11</a></li>
<li><a href="https://mxnet.apache.org/versions/1.6/api/python/docs/api/mxnet/context/index.html">Context management API of mxnet.</a></li>
</ul>
<h4 id="source"><a href="https://www.digitalocean.com/community/tutorials/install-cuda-cudnn-for-gpu">Source</a></h4>
<!-- raw HTML omitted -->

			</div>
		</article>
	</main>
<aside>
	<div>
		<div>
			<h3>LATEST POSTS</h3>
		</div>
		<div>
			<ul>
				
				<li><a href="/posts/2025-03-20-laser-harp-sets-the-tone/">Laser Harp Sets the Tone</a></li>
				
				<li><a href="/posts/2025-03-20-arduino-device-helps-split-the-g-on-a-p/">Arduino device helps split the G on a pint of Guinness</a></li>
				
				<li><a href="/posts/2025-03-20-the-70-best-early-amazon-spring-sale-ga/">The 70 best early Amazon Spring Sale gaming deals 2025</a></li>
				
				<li><a href="/posts/2025-03-20-tomorrow-and-tomorrow-and-tomorrow-info/">Tomorrow and tomorrow and tomorrow Information security and the Baseball Hall of Fame</a></li>
				
				<li><a href="/posts/2025-03-20-i-found-an-android-phone-that-can-convi/">I found an Android phone that can convince iPhone users to make the switch - and its not a flagship</a></li>
				
			</ul>
		</div>
	</div>
</aside>


	<footer>
	<p>&copy; 2025 <a href="https://ghariib.ir/"><b>Alireza Gharib. All right reserved</b></a>.
	<a href="https://github.com/Gharib110"><b>Github</b></a>.
	</p>
</footer>

</body>
</html>
