<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cyberattack on Gharib Personal Blog</title>
    <link>https://ghariib.ir/categories/cyberattack/</link>
    <description>Recent content in Cyberattack on Gharib Personal Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>Alireza Gharib. All right reserved</copyright>
    <lastBuildDate>Thu, 06 Feb 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://ghariib.ir/categories/cyberattack/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>&lt;div&gt;On Generative AI Security&lt;/div&gt;</title>
      <link>https://ghariib.ir/posts/on-generative-ai-security/</link>
      <pubDate>Thu, 06 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://ghariib.ir/posts/on-generative-ai-security/</guid>
      <description>&lt;p&gt;Microsoft’s AI Red Team just published “Lessons from&lt;br&gt;&#xA;Red Teaming 100 Generative AI Products.” Their blog post lists “three takeaways,” but the eight lessons in the report itself are more useful:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Understand what the system can do and where it is applied.&lt;/li&gt;&#xA;&lt;li&gt;You don’t have to compute gradients to break an AI system.&lt;/li&gt;&#xA;&lt;li&gt;AI red teaming is not safety benchmarking.&lt;/li&gt;&#xA;&lt;li&gt;Automation can help cover more of the risk landscape.&lt;/li&gt;&#xA;&lt;li&gt;The human element of AI red teaming is crucial.&lt;/li&gt;&#xA;&lt;li&gt;Responsible AI harms are pervasive but difficult to measure.&lt;/li&gt;&#xA;&lt;li&gt;LLMs amplify existing security risks and introduce new ones&amp;hellip;&lt;/li&gt;&#xA;&lt;/ol&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;Microsoft’s AI Red Team just published “Lessons from&lt;br&gt;&#xA;Red Teaming 100 Generative AI Products.” Their blog post lists “three takeaways,” but the eight lessons in the report itself are more useful:&lt;/p&gt;</description>
    </item>
    <item>
      <title>&lt;div&gt;CISA Under Trump&lt;/div&gt;</title>
      <link>https://ghariib.ir/posts/cisa-under-trump/</link>
      <pubDate>Wed, 29 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://ghariib.ir/posts/cisa-under-trump/</guid>
      <description>&lt;p&gt;Jen Easterly is out as the Director of CISA. Read her final interview:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;There’s a lot of unfinished business. We have made an impact through our ransomware vulnerability warning pilot and our pre-ransomware notification initiative, and I’m really proud of that, because we work on preventing somebody from having their worst day. But ransomware is still a problem. We have been laser-focused on PRC cyber actors. That will continue to be a huge problem. I’m really proud of where we are, but there’s much, much more work to be done. There are things that I think we can continue driving, that the next administration, I hope, will look at, because, frankly, cybersecurity is a national security issue&amp;hellip;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
